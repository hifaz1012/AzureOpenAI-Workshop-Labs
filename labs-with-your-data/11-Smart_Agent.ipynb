{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6423f8f3-a592-4ee7-9969-39e38933be52",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bf854d-94d7-4a65-952a-22c7999a9a9b",
   "metadata": {},
   "source": [
    "So far we have done the following on the prior Notebooks:\n",
    "\n",
    "- **Notebook 01**: We loaded the Azure Search Engine with enriched PDFs in index: \"cogsrch-index-files\"\n",
    "- **Notebook 02**: We loaded more information to the Search Engine this time using a CSV file with 90k rows/articles in index: \"cogsrch-index-csv\"\n",
    "- **Notebook 03**: We added AzureOpenAI GPT models to enhance the the production of the answer by using Utility Chains of LLMs\n",
    "- **Notebook 04**: We manually loaded an index with large/complex PDFs information , \"cogsrch-index-books-vector\"\n",
    "- **Notebook 05**: We added memory to our system in order to power a conversational Chat Bot\n",
    "- **Notebook 06**: We introduced Agents and Tools and built the first Skill/Agent, that can do RAG over a search engine\n",
    "- **Notebook 07**: We build a second Agent (Pandas) in order to be able to solve a more complex task: ask questions to Tabular datasets\n",
    "- **Notebook 08**: We used a SQL Agent in order to talk to a SQL Database directly\n",
    "- **Notebook 09**: We used another  Agent in order to talk to the Bing Search API and create a Bing Chat Clone and implemented callbacks for real-time streaming and tool information\n",
    "- **Notebook 10**: We built an API Agent that can translate a question into the right API calls, giving us the capability to talk to any datasource that provides a RESTFul API.\n",
    "\n",
    "\n",
    "We are missing one more thing: **How do we glue all these features together into a very smart GPT Smart Search Engine Chat Bot?**\n",
    "\n",
    "We want a virtual assistant for our company that can get the question, think what tool to use, then get the answer. The goal is that, regardless of the source of the information (Search Engine, Bing Search, SQL Database, CSV File, JSON File, APIs, etc), the Assistant can answer the question correctly using the right tool.\n",
    "\n",
    "In this Notebook we are going to create that \"brain\" Agent (also called Master Agent), that:\n",
    "\n",
    "1) understands the question, interacts with the user \n",
    "2) talks to other specialized Agents that are connected to diferent sources\n",
    "3) once it get's the answer it delivers it to the user or let the specialized Agent to deliver it directly\n",
    "\n",
    "This is the same concept of [AutoGen](https://www.microsoft.com/en-us/research/blog/autogen-enabling-next-generation-large-language-model-applications/): Agents talking to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7fa9dc-64cb-4ee2-ae98-8cdb72293cbe",
   "metadata": {},
   "source": [
    "![image](https://www.microsoft.com/en-us/research/uploads/prod/2023/09/AutoGen_Fig1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30b81551-92ac-4f08-9c00-ba11981c67c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import requests\n",
    "from operator import itemgetter\n",
    "from typing import Union, List\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.agents import AgentExecutor, Tool, create_openai_tools_agent\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory, CosmosDBChatMessageHistory\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.runnables import ConfigurableFieldSpec, ConfigurableField\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.output_parsers import JsonOutputToolsParser\n",
    "from langchain_core.runnables import (\n",
    "    Runnable,\n",
    "    RunnableLambda,\n",
    "    RunnableMap,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "\n",
    "#custom libraries that we will use later in the app\n",
    "from common.utils import (\n",
    "    DocSearchAgent, \n",
    "    CSVTabularAgent, \n",
    "    SQLSearchAgent, \n",
    "    ChatGPTTool, \n",
    "    BingSearchAgent, \n",
    "    APISearchAgent, \n",
    "    reduce_openapi_spec\n",
    ")\n",
    "from common.callbacks import StdOutCallbackHandler\n",
    "from common.prompts import CUSTOM_CHATBOT_PROMPT \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials.env\")\n",
    "\n",
    "from IPython.display import Markdown, HTML, display \n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67cd1e3e-8527-4a8f-ba90-e700ae7b20ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b56a94-0471-41c3-b441-3a73ff5dedfc",
   "metadata": {},
   "source": [
    "### Get the Tools - DocSearch Agent, CSV Agent, SQL Agent, Web Search Agent, ChatGPT, API Agent\n",
    "\n",
    "**Consider the following concept:** Agents, which are essentially software entities designed to perform specific tasks, can be equipped with tools. These tools themselves can be other agents, each possessing their own set of tools. This creates a layered structure where tools can range from code sequences to human actions, forming interconnected chains. Ultimately, you're constructing a network of agents and their respective tools, all collaboratively working towards solving a specific task (This is what ChatGPT is). This network operates by leveraging the unique capabilities of each agent and tool, creating a dynamic and efficient system for task resolution.\n",
    "\n",
    "In the file `common/utils.py` we created Agent Tools Classes for each of the Functionalities that we developed in prior Notebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "643d1650-6416-46fd-8b21-f5fb298ec063",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_handler = StdOutCallbackHandler()\n",
    "cb_manager = CallbackManager(handlers=[cb_handler])\n",
    "\n",
    "COMPLETION_TOKENS = 2000\n",
    "\n",
    "# We can run the everything with GPT3.5, but try also GPT4 and see the difference in the quality of responses\n",
    "# You will notice that GPT3.5 is not as reliable when using multiple sources.\n",
    "\n",
    "llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT4_DEPLOYMENT_NAME\"], \n",
    "                      temperature=0, max_tokens=COMPLETION_TOKENS)\n",
    "\n",
    "# Uncomment below if you want to see the answers streaming\n",
    "# llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT4_DEPLOYMENT_NAME\"], temperature=0, max_tokens=COMPLETION_TOKENS, streaming=True, callback_manager=cb_manager)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6a4cc93-2dd6-45eb-ac5b-5af2d31809dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_indexes = [\"cogsrch-index-files\", \"cogsrch-index-csv\"]\n",
    "doc_search = DocSearchAgent(llm=llm, indexes=doc_indexes,\n",
    "                           k=6, reranker_th=1,\n",
    "                           sas_token=os.environ['BLOB_SAS_TOKEN'],\n",
    "                           name=\"docsearch\",\n",
    "                           description=\"useful when the questions includes the term: docsearch\",\n",
    "                           callback_manager=cb_manager, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eafd5bf5-28ee-4edd-978b-384cce057257",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_indexes = [\"cogsrch-index-books\"]\n",
    "book_search = DocSearchAgent(llm=llm, indexes=book_indexes,\n",
    "                           k=10, reranker_th=1,\n",
    "                           sas_token=os.environ['BLOB_SAS_TOKEN'],\n",
    "                           name=\"booksearch\",\n",
    "                           description=\"useful when the questions includes the term: booksearch\",\n",
    "                           callback_manager=cb_manager, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f0ae466-aff8-4cdf-80d3-ef2c61867fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BingSearchAgent is a langchain Tool class to use the Bing Search API (https://www.microsoft.com/en-us/bing/apis/bing-web-search-api)\n",
    "www_search = BingSearchAgent(llm=llm, k=5, callback_manager=cb_manager, \n",
    "                             name=\"bing\",\n",
    "                             description=\"useful when the questions includes the term: bing\",\n",
    "                             verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78edb304-c4a2-4f10-8ded-936e9141aa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CSVTabularAgent is a custom Tool class crated to Q&A over CSV files\n",
    "file_url = \"./data/all_states/all-states-history.csv\"\n",
    "csv_search = CSVTabularAgent(path=file_url, llm=llm, callback_manager=cb_manager,\n",
    "                             name=\"csvfile\",\n",
    "                             description=\"useful when the questions includes the term: csvfile\",\n",
    "                             verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9d54cc5-41bc-43c3-a91d-12fc3a2446ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SQLDbAgent is a custom Tool class created to Q&A over a MS SQL Database\n",
    "sql_search = SQLSearchAgent(llm=llm, k=30, callback_manager=cb_manager,\n",
    "                            name=\"sqlsearch\",\n",
    "                            description=\"useful when the questions includes the term: sqlsearch\",\n",
    "                            verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65465173-92f6-489d-9b48-58d109c5723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ChatGPTTool is a custom Tool class created to talk to ChatGPT knowledge\n",
    "chatgpt_search = ChatGPTTool(llm=llm, callback_manager=cb_manager,\n",
    "                             name=\"chatgpt\",\n",
    "                            description=\"useful when the questions includes the term: chatgpt\",\n",
    "                            verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fe2b4a7-4053-4334-867f-e4c916e360b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## APISearchAgent is a custom Tool class created to talk to any API \n",
    "\n",
    "spec = json.load(open(\"./data/api_specs/kraken.json\", encoding='utf-8'))\n",
    "\n",
    "api_search = APISearchAgent(llm=AzureChatOpenAI(deployment_name=os.environ[\"GPT4_DEPLOYMENT_NAME\"], temperature=0.5, max_tokens=1000),\n",
    "                            llm_search=AzureChatOpenAI(deployment_name=os.environ[\"GPT4_DEPLOYMENT_NAME\"], temperature=0.5, max_tokens=1000),\n",
    "                            api_spec=str(reduce_openapi_spec(spec)),\n",
    "                            callback_manager=cb_manager,\n",
    "                            name=\"apisearch\",\n",
    "                            description=\"useful when the questions includes the term: apisearch\",\n",
    "                            verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179fc56a-b7e4-44a1-8b7f-68b2b4d02e13",
   "metadata": {},
   "source": [
    "### Variables/knobs to use for customization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f11831-7578-4326-b3b3-d9b073a7149d",
   "metadata": {},
   "source": [
    "As you have seen so far, there are many knobs that you can dial up or down in order to change the behavior of your GPT Smart Search engine application, these are the variables you can tune:\n",
    "\n",
    "- <u>llm</u>:\n",
    "  - **deployment_name**: this is the deployment name of your Azure OpenAI model. This of course dictates the level of reasoning and the amount of tokens available for the conversation. \n",
    "  - **temperature**: How creative you want your responses to be\n",
    "  - **max_tokens**: How long you want your responses to be. It is recommended a minimum of 500\n",
    "- <u>Tools</u>: To each tool you can add the following parameters to modify the defaults (set in utils.py), these are very important since they are part of the system prompt and determines what tool to use and when.\n",
    "  - **name**: the name of the tool\n",
    "  - **description**: when the brain agent should use this tool\n",
    "- <u>DocSearchAgent</u>: \n",
    "  - **k**: The top k results per index from the text search action\n",
    "  - **similarity_k**: top k results combined from the vector search action\n",
    "  - **reranker_th**: threshold of the semantic search reranker. Picks results that are above the threshold. Max possible score=4\n",
    "- <u>BingSearchAgent</u>:\n",
    "  - **k**: The top k results from the bing search action\n",
    "- <u>SQLSearchAgent</u>:\n",
    "  - **k**: The top k results from the SQL search action. Adds TOP clause to the query\n",
    "  \n",
    "in `utils.py` you can also tune:\n",
    "- <u>model_tokens_limit</u>: In this function you can edit what is the maximum allows of tokens reserve for the content. Remember that the remaining will be for the system prompt plus the answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ee1058-debb-4f97-92a4-999e0c4e0386",
   "metadata": {},
   "source": [
    "### Test the Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "473222f1-b423-49f3-98e7-ab70dcf47bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: docsearch\n",
      "Agent Action: \n",
      "Invoking: `docsearch` with `{'query': 'Covid effects on obese people'}`\n",
      "\n",
      "\n",
      "\n",
      "Agent Action: \n",
      "Invoking: `docsearch` with `{'query': 'Covid effects on elderly people'}`\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Impact of COVID-19 on Obese People\n",
       "\n",
       "Obesity has been identified as a significant risk factor for severe outcomes in COVID-19 patients. Obese individuals are more likely to experience severe symptoms, require hospitalization, and have a higher risk of mortality. The reasons for this increased risk include:\n",
       "\n",
       "1. **Impaired Immune Response**: Obesity can impair the immune system, making it less effective at fighting off infections, including COVID-19.\n",
       "2. **Chronic Inflammation**: Obesity is associated with chronic low-grade inflammation, which can exacerbate the inflammatory response to COVID-19, leading to more severe symptoms.\n",
       "3. **Respiratory Issues**: Excess weight can restrict lung function and make it more difficult for obese individuals to breathe, which is particularly problematic with a respiratory illness like COVID-19.\n",
       "4. **Comorbidities**: Obese individuals often have other health conditions such as diabetes, hypertension, and cardiovascular diseases, which can complicate COVID-19 treatment and recovery [[1]](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1143779/?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2025-01-30T14:55:42Z&st=2024-07-10T06:55:42Z&spr=https&sig=NQgAnpUqrSUPKdOZwtvdSQP2pjwoeUK0xlNtd%2F554t8%3D).\n",
       "\n",
       "### Impact of COVID-19 on Elderly People\n",
       "\n",
       "Elderly individuals are particularly vulnerable to COVID-19 due to several factors:\n",
       "\n",
       "1. **Weakened Immune System**: Aging is associated with a decline in immune function, making it harder for elderly individuals to fight off infections.\n",
       "2. **Higher Prevalence of Comorbidities**: Older adults are more likely to have chronic health conditions such as heart disease, diabetes, and respiratory diseases, which can worsen the prognosis of COVID-19.\n",
       "3. **Increased Risk of Severe Outcomes**: Studies have shown that elderly patients are more likely to experience severe symptoms, require intensive care, and have higher mortality rates compared to younger populations.\n",
       "4. **Impact of Social Isolation**: Measures to reduce contact, such as social distancing and lockdowns, can have significant mental health impacts on the elderly, potentially exacerbating feelings of loneliness and depression [[2]](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2876165/?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2025-01-30T14:55:42Z&st=2024-07-10T06:55:42Z&spr=https&sig=NQgAnpUqrSUPKdOZwtvdSQP2pjwoeUK0xlNtd%2F554t8%3D).\n",
       "\n",
       "In summary, both obese and elderly individuals face heightened risks from COVID-19 due to a combination of physiological vulnerabilities and the presence of comorbid conditions. It is crucial for these populations to take extra precautions and for healthcare systems to prioritize their protection and treatment."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the Document Search Tool with a question that we know it has the answer for\n",
    "printmd(await doc_search.arun(\"How Covid affects obese people? and elderly?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03839591-553c-46a0-846a-1c4fb96bf851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: bing\n",
      "Agent Action: \n",
      "Invoking: `Searcher` with `{'query': 'current president of India family members names'}`\n",
      "\n",
      "\n",
      "\n",
      "Agent Action: \n",
      "Invoking: `Searcher` with `{'query': 'Droupadi Murmu family members names'}`\n",
      "\n",
      "\n",
      "\n",
      "Agent Action: \n",
      "Invoking: `WebFetcher` with `{'url': 'https://starsunfolded.com/droupadi-murmu/'}`\n",
      "\n",
      "\n",
      "\n",
      "Agent Action: \n",
      "Invoking: `Searcher` with `{'query': 'Droupadi Murmu family members names site:starsunfolded.com'}`\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The current President of India, Droupadi Murmu, has the following family members:\n",
       "\n",
       "1. **Husband**: Shyam Charan Murmu (deceased) [[1]](https://starsunfolded.com/droupadi-murmu/).\n",
       "2. **Daughter**: Itishree Murmu [[2]](https://starsunfolded.com/itishree-murmu/).\n",
       "\n",
       "Droupadi Murmu has faced significant personal losses, including the deaths of her husband and two sons within a span of six years [[1]](https://starsunfolded.com/droupadi-murmu/).\n",
       "\n",
       "For more detailed information, you can visit the [Stars Unfolded page on Droupadi Murmu](https://starsunfolded.com/droupadi-murmu/)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the Bing Search Agent\n",
    "printmd(await www_search.arun(\"Who are the family member names of the current president of India?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f70501c2-03d0-4072-b451-ddb92f4add56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: chatgpt\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "En Python, puedes obtener un número aleatorio utilizando la biblioteca `random`. Esta biblioteca proporciona varias funciones para generar números aleatorios. La función más comúnmente utilizada para obtener un número aleatorio dentro de un rango específico es `random.randint(a, b)`, donde `a` y `b` son los límites inferior y superior del rango, respectivamente.\n",
       "\n",
       "Aquí tienes un ejemplo de cómo usar `random.randint`:\n",
       "\n",
       "```python\n",
       "import random\n",
       "\n",
       "# Generar un número aleatorio entre 1 y 10\n",
       "numero_aleatorio = random.randint(1, 10)\n",
       "print(numero_aleatorio)\n",
       "```\n",
       "\n",
       "Además de `random.randint`, la biblioteca `random` ofrece otras funciones útiles para generar números aleatorios:\n",
       "\n",
       "- `random.random()`: Devuelve un número flotante aleatorio entre 0.0 y 1.0.\n",
       "- `random.uniform(a, b)`: Devuelve un número flotante aleatorio entre `a` y `b`.\n",
       "- `random.choice(seq)`: Devuelve un elemento aleatorio de una secuencia (como una lista o una cadena).\n",
       "\n",
       "Aquí tienes ejemplos de estas funciones:\n",
       "\n",
       "```python\n",
       "import random\n",
       "\n",
       "# Número flotante aleatorio entre 0.0 y 1.0\n",
       "numero_flotante = random.random()\n",
       "print(numero_flotante)\n",
       "\n",
       "# Número flotante aleatorio entre 1.5 y 6.5\n",
       "numero_uniforme = random.uniform(1.5, 6.5)\n",
       "print(numero_uniforme)\n",
       "\n",
       "# Elemento aleatorio de una lista\n",
       "lista = [1, 2, 3, 4, 5]\n",
       "elemento_aleatorio = random.choice(lista)\n",
       "print(elemento_aleatorio)\n",
       "```\n",
       "\n",
       "Para más información sobre la biblioteca `random`, puedes consultar la [documentación oficial de Python](https://docs.python.org/3/library/random.html)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the ChatGPTWrapper Search Tool\n",
    "printmd(await chatgpt_search.arun(\"what is the function in python that allows me to get a random number?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0ff658-b75a-4960-8576-65472844ad05",
   "metadata": {},
   "source": [
    "### Define what tools are we going to give to our brain agent\n",
    "\n",
    "Go to `common/utils.py` to check the tools definition and the instructions on what tool to use when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d018c884-5c91-4a35-90e3-6a5a6e510c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [www_search, sql_search, doc_search, book_search, chatgpt_search]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f91421-079d-4bdd-9c45-96a0977c6558",
   "metadata": {},
   "source": [
    "**Note**: Notice that since both the CSV file and the SQL Database have the same exact data, we are only going to use the SQLDBTool since it is faster and more reliable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27699991-00d8-4f0a-8511-e03e530910c3",
   "metadata": {},
   "source": [
    "# Option 1: Using OpenAI functions as router"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aed5eb-846d-44d1-acf1-04b8ff931d30",
   "metadata": {},
   "source": [
    "We need a method to route the question to the right tool, one simple way to do this is to use OpenAI models functions via the Tools API (models 1106 and newer). To do this, we need to bind these tools/functions to the model and let the model respond with the right tool to use.\n",
    "\n",
    "The advantage of this option is that there is no another agent in the middle between the experts (agent tools) and the user. Each agent tool responds directly. Also, another advantage is that multiple tools can be called in parallel.\n",
    "\n",
    "**Note**: on this method it is important that each agent tool has the same system profile prompt so they adhere to the same reponse guidelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "218163af-2279-4891-8699-7f9f291c49f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)\n",
    "tool_map = {tool.name: tool for tool in tools}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c5e8efd-b907-4157-99f8-15a44a63f17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_tool(tool_invocation: dict) -> Union[str, Runnable]:\n",
    "    \"\"\"Function for dynamically constructing the end of the chain based on the model-selected tool.\"\"\"\n",
    "    tool = tool_map[tool_invocation[\"type\"]]\n",
    "    return RunnablePassthrough.assign(output=itemgetter(\"args\") | tool)\n",
    "\n",
    "def print_response(result: List):\n",
    "    for answer in result:\n",
    "        printmd(\"**\"+answer[\"type\"] + \"**\" + \": \" + answer[\"output\"])\n",
    "        printmd(\"----\")\n",
    "    \n",
    "# .map() allows us to apply a function to a list of inputs.\n",
    "call_tool_list = RunnableLambda(call_tool).map()\n",
    "agent = llm_with_tools | JsonOutputToolsParser() | call_tool_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63682613-daa3-49fa-9fe0-6e5af8ff05ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: bing\n",
      "Agent Action: \n",
      "Invoking: `Searcher` with `{'query': 'current president of France 2023'}`\n",
      "\n",
      "\n",
      "\n",
      "Agent Action: \n",
      "Invoking: `WebFetcher` with `{'url': 'https://www.elysee.fr/en/emmanuel-macron'}`\n",
      "\n",
      "\n",
      "\n",
      "Agent Action: \n",
      "Invoking: `Searcher` with `{'query': 'current president of France site:elysee.fr'}`\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**bing**: The current President of France is Emmanuel Macron. He was first elected on May 7, 2017, and re-elected on April 24, 2022 [[1]](https://www.elysee.fr/en/emmanuel-macron)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = agent.invoke(\"Who is the current president of France?\")\n",
    "print_response(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f58b57b-51cb-433c-b6a8-376e6aa06e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: docsearch\n",
      "Tool: bing\n",
      "Agent Action: \n",
      "Invoking: `docsearch` with `{'query': 'CLP'}`\n",
      "\n",
      "\n",
      "\n",
      "Agent Action: \n",
      "Invoking: `Searcher` with `{'query': 'CLP'}`\n",
      "\n",
      "\n",
      "\n",
      "Agent Action: \n",
      "Invoking: `WebFetcher` with `{'url': 'https://www.clp.com.hk/en/index'}`\n",
      "\n",
      "\n",
      "\n",
      "Agent Action: \n",
      "Invoking: `WebFetcher` with `{'url': 'https://www.clpgroup.com/en/index.html'}`\n",
      "\n",
      "\n",
      "\n",
      "Agent Action: \n",
      "Invoking: `Searcher` with `{'query': 'site:clp.com.hk'}`\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**docsearch**: El término \"CLP\" puede referirse a varios conceptos dependiendo del contexto. Aquí hay algunos ejemplos basados en los documentos encontrados:\n",
       "\n",
       "1. **Proteasa 3C-Like (3CLpro)**: En el contexto de los virus, como el SARS-CoV, la proteasa 3C-Like (3CLpro) es una enzima crucial para el procesamiento proteolítico de los polipéptidos replicativos del virus. Esta enzima es un objetivo prometedor para el desarrollo de fármacos anti-SARS debido a su papel esencial en la replicación viral [[source]](https://onlinelibrary.wiley.com/doi/pdfdirect/10.1110/ps.052007306?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2025-01-30T14:55:42Z&st=2024-07-10T06:55:42Z&spr=https&sig=NQgAnpUqrSUPKdOZwtvdSQP2pjwoeUK0xlNtd%2F554t8%3D).\n",
       "\n",
       "2. **Tripeptidil-peptidasa I (CLN2)**: En el contexto de enfermedades neurodegenerativas, la tripeptidil-peptidasa I, también conocida como CLN2, es una enzima cuya deficiencia en humanos conduce a la ceroidolipofuscinosis neuronal infantil tardía, una enfermedad neurodegenerativa fatal. Esta enzima es altamente conservada y ampliamente distribuida entre los organismos superiores [[source]](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC280685/?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2025-01-30T14:55:42Z&st=2024-07-10T06:55:42Z&spr=https&sig=NQgAnpUqrSUPKdOZwtvdSQP2pjwoeUK0xlNtd%2F554t8%3D).\n",
       "\n",
       "3. **Proteasa 3CL en PRRSV**: En el contexto del virus del síndrome reproductivo y respiratorio porcino (PRRSV), la proteasa 3CL juega un papel crucial en la maquinaria de transcripción y replicación del virus. Esta enzima ha sido clonada y sobreexpresada en Escherichia coli para estudios de cristalización [[source]](http://europepmc.org/articles/pmc2335157?pdf=render?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2025-01-30T14:55:42Z&st=2024-07-10T06:55:42Z&spr=https&sig=NQgAnpUqrSUPKdOZwtvdSQP2pjwoeUK0xlNtd%2F554t8%3D).\n",
       "\n",
       "Estos son solo algunos ejemplos de cómo se puede interpretar \"CLP\" en diferentes contextos científicos."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**bing**: CLP (China Light and Power) is a major electricity company with a significant presence in Hong Kong and other regions. Here are some key details about CLP:\n",
       "\n",
       "### Overview\n",
       "- **CLP Power Hong Kong Limited** is a wholly-owned subsidiary of CLP Holdings Limited. Founded in 1901, it provides electricity to more than 80% of Hong Kong’s population [[1]](https://www.clp.com.hk/en/index).\n",
       "- CLP Holdings Limited is a listed company in Hong Kong and one of the largest investor-owned power businesses in Asia. It operates as a vertically integrated power utility covering power generation, transmission, and distribution [[2]](https://www.clp.com.hk/en/about-clp).\n",
       "\n",
       "### Services and Operations\n",
       "- **Power Generation**: CLP generates electricity through various means, including renewable energy sources.\n",
       "- **Power Transmission and Distribution**: The company ensures the reliable delivery of electricity to its customers.\n",
       "- **Customer Services**: CLP offers online services for billing, payment, and customer support. They also have a rewards program and provide energy-saving tips [[3]](https://www.clp.com.hk/en/help-support).\n",
       "\n",
       "### Additional Information\n",
       "- **Website**: For more detailed information, you can visit their official website [here](https://www.clp.com.hk/en/index).\n",
       "\n",
       "If you need more specific details or have any other questions, feel free to ask!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = agent.invoke(\"docsearch,bing, what is CLP?\")\n",
    "print_response(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb036da4-825f-45a4-a08f-c5a272c8f895",
   "metadata": {},
   "source": [
    "# Option 2: Using a user facing agent that calls the agent tools experts\n",
    "\n",
    "With this method, we create a user facing agent that talks to the user and also talks to the experts (agent tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc02389-cf52-4a5f-b4a1-2820ee5d8116",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Initialize the brain agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea67e969-26b3-4e6f-a6c0-16780ed418e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_openai_tools_agent(llm, tools, CUSTOM_CHATBOT_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9d2d5b4-0145-402e-a620-0fe3f3548acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e3ffef69-5dcd-423a-802d-7a0c419c7e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id: str, user_id: str) -> CosmosDBChatMessageHistory:\n",
    "    cosmos = CosmosDBChatMessageHistory(\n",
    "        cosmos_endpoint=os.environ['AZURE_COSMOSDB_ENDPOINT'],\n",
    "        cosmos_database=os.environ['AZURE_COSMOSDB_NAME'],\n",
    "        cosmos_container=os.environ['AZURE_COSMOSDB_CONTAINER_NAME'],\n",
    "        connection_string=os.environ['AZURE_COMOSDB_CONNECTION_STRING'],\n",
    "        session_id=session_id,\n",
    "        user_id=user_id\n",
    "        )\n",
    "\n",
    "    # prepare the cosmosdb instance\n",
    "    cosmos.prepare_cosmos()\n",
    "    return cosmos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73e389f9-17cc-4c12-80e0-ab671b46bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_agent_executor = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\",\n",
    "    history_factory_config=[\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"user_id\",\n",
    "            annotation=str,\n",
    "            name=\"User ID\",\n",
    "            description=\"Unique identifier for the user.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"session_id\",\n",
    "            annotation=str,\n",
    "            name=\"Session ID\",\n",
    "            description=\"Unique identifier for the conversation.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "601fce84-4a02-41a6-8ae2-f692174d4cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session118 user356\n"
     ]
    }
   ],
   "source": [
    "# This is where we configure the session id and user id\n",
    "random_session_id = \"session\"+ str(random.randint(1, 1000))\n",
    "ramdom_user_id = \"user\"+ str(random.randint(1, 1000))\n",
    "\n",
    "config={\"configurable\": {\"session_id\": random_session_id, \"user_id\": ramdom_user_id}}\n",
    "print(random_session_id, ramdom_user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4904a07d-b857-45d7-86ac-c7cade3e9080",
   "metadata": {},
   "source": [
    "### Let's talk to our GPT Smart Search Engine chat bot now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d0b33f9-75fa-4a3e-b9d8-8fd30dbfd3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In physics, the formula for momentum (\\( p \\)) is given by:\n",
       "\n",
       "\\[ p = m \\cdot v \\]\n",
       "\n",
       "where:\n",
       "- \\( p \\) is the momentum,\n",
       "- \\( m \\) is the mass of the object,\n",
       "- \\( v \\) is the velocity of the object.\n",
       "\n",
       "Momentum is a vector quantity, which means it has both magnitude and direction. The direction of the momentum vector is the same as the direction of the velocity vector."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd(brain_agent_executor.invoke({\"question\": \"tell me the formula in physics for momentum\"}, config=config)[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94f354eb-884d-4fd3-842e-a8adc3b09a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: docsearch\n",
      "Agent Action: \n",
      "Invoking: `docsearch` with `{'query': 'NP-complete problem'}`\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Un problema **NP-completo** es un tipo de problema en la teoría de la complejidad computacional que tiene dos características principales:\n",
       "\n",
       "1. **NP (Nondeterministic Polynomial time)**: Un problema está en NP si una solución propuesta para el problema puede ser verificada como correcta o incorrecta en tiempo polinómico por una máquina de Turing determinista. En otras palabras, si se te da una solución, puedes verificar su corrección rápidamente.\n",
       "\n",
       "2. **NP-duro**: Un problema es NP-duro si cualquier problema en NP puede ser transformado (reducido) en tiempo polinómico a este problema. Esto implica que resolver un problema NP-duro es al menos tan difícil como resolver cualquier otro problema en NP.\n",
       "\n",
       "Un problema es NP-completo si cumple ambas condiciones anteriores: está en NP y es NP-duro. Esto implica que si se encuentra un algoritmo de tiempo polinómico para resolver cualquier problema NP-completo, entonces todos los problemas en NP pueden ser resueltos en tiempo polinómico, lo cual resolvería la famosa pregunta de si P = NP.\n",
       "\n",
       "### Ejemplo de Problema NP-completo\n",
       "\n",
       "Un ejemplo de un problema NP-completo es la predicción de estructuras de pseudonudos en el ARN, que es crucial en procesos virales y celulares. Los algoritmos prácticos para la predicción de estructuras de ARN, incluyendo clases restringidas de pseudonudos, sufren de tiempos de ejecución elevados y baja precisión para secuencias largas [[1]](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2853144/?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2025-01-30T14:55:42Z&st=2024-07-10T06:55:42Z&spr=https&sig=NQgAnpUqrSUPKdOZwtvdSQP2pjwoeUK0xlNtd%2F554t8%3D).\n",
       "\n",
       "Para más detalles sobre problemas NP-completos y su relevancia en diferentes campos, puedes consultar la literatura especializada en teoría de la complejidad computacional y algoritmos."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd(brain_agent_executor.invoke({\"question\": \"docsearch, what is a NP-complete problem?\"}, config=config)[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "badebc1b-dbfe-4a92-93bd-9ff214c34e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: sqlsearch\n",
      "Agent Action: \n",
      "Invoking: `sql_db_list_tables` with `{}`\n",
      "\n",
      "\n",
      "\n",
      "Agent Action: \n",
      "Invoking: `sql_db_schema` with `{'table_names': 'covidtracking'}`\n",
      "\n",
      "\n",
      "\n",
      "Agent Action: \n",
      "Invoking: `sql_db_query_checker` with `{'query': \"SELECT SUM(death) AS total_deaths FROM covidtracking WHERE state = 'TX' AND date LIKE '2021%'\"}`\n",
      "\n",
      "\n",
      "\n",
      "Agent Action: \n",
      "Invoking: `sql_db_query` with `{'query': \"SELECT SUM(death) AS total_deaths FROM covidtracking WHERE state = 'TX' AND date LIKE '2021%'\"}`\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "In 2021, a total of 76,573 people died of COVID-19 in Texas.\n",
       "\n",
       "This information was obtained by querying the `covidtracking` table for the sum of the `death` column where the state is 'TX' and the date starts with '2021'. The SQL query used was:\n",
       "\n",
       "```sql\n",
       "SELECT SUM(death) AS total_deaths FROM covidtracking WHERE state = 'TX' AND date LIKE '2021%'\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd(brain_agent_executor.invoke({\"question\": \"sqlsearch, How many people died of covid in Texas in 2021?\"}, config=config)[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1fcd6749-b36d-4b5c-be9c-e2f02f34d230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: bing\n",
      "Agent Action: \n",
      "Invoking: `Searcher` with `{'query': 'best places to dine in downtown Seoul'}`\n",
      "\n",
      "\n",
      "\n",
      "Agent Action: \n",
      "Invoking: `Searcher` with `{'query': 'top restaurants in downtown Seoul 2023'}`\n",
      "\n",
      "\n",
      "\n",
      "Agent Action: \n",
      "Invoking: `WebFetcher` with `{'url': 'https://www.tripadvisor.com/Restaurants-g294197-Seoul.html'}`\n",
      "\n",
      "\n",
      "\n",
      "Agent Action: \n",
      "Invoking: `WebFetcher` with `{'url': 'https://www.eater.com/maps/best-seoul-restaurants-38'}`\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Based on the search results, here are some highly recommended places to dine in downtown Seoul:\n",
       "\n",
       "### 1. **Mosu**\n",
       "- **Description**: Recently elevated to a three-star Michelin restaurant, Mosu offers an exquisite dining experience with a focus on innovative Korean cuisine.\n",
       "- **Link**: [Michelin Guide Seoul 2023](https://www.finedininglovers.com/article/michelin-stars-seoul-2023)\n",
       "\n",
       "### 2. **Jungsik**\n",
       "- **Description**: A two-star Michelin restaurant known for its modern take on traditional Korean dishes.\n",
       "- **Link**: [Michelin Guide Seoul 2023](https://guide.michelin.com/sg/en/article/travel/5-new-michelin-starred-restaurants-in-seoul-en-2023-sg)\n",
       "\n",
       "### 3. **Mingles**\n",
       "- **Description**: Another two-star Michelin restaurant that blends Korean and Western culinary techniques.\n",
       "- **Link**: [Michelin Guide Seoul 2023](https://guide.michelin.com/sg/en/article/travel/5-new-michelin-starred-restaurants-in-seoul-en-2023-sg)\n",
       "\n",
       "### 4. **TocToc**\n",
       "- **Description**: A one-star Michelin restaurant offering a unique dining experience with a focus on seasonal ingredients.\n",
       "- **Link**: [Michelin Guide Seoul 2023](https://guide.michelin.com/sg/en/article/travel/5-new-michelin-starred-restaurants-in-seoul-en-2023-sg)\n",
       "\n",
       "### 5. **Balwoo Gongyang**\n",
       "- **Description**: A one-star Michelin restaurant that specializes in temple cuisine, offering a serene and spiritual dining experience.\n",
       "- **Link**: [Michelin Guide Seoul 2023](https://guide.michelin.com/sg/en/article/travel/5-new-michelin-starred-restaurants-in-seoul-en-2023-sg)\n",
       "\n",
       "### 6. **Joo Ok**\n",
       "- **Description**: Known for its creative and modern Korean dishes, Joo Ok is a one-star Michelin restaurant that promises a memorable dining experience.\n",
       "- **Link**: [Michelin Guide Seoul 2023](https://guide.michelin.com/sg/en/article/travel/5-new-michelin-starred-restaurants-in-seoul-en-2023-sg)\n",
       "\n",
       "### 7. **Gaon**\n",
       "- **Description**: A three-star Michelin restaurant that offers a luxurious dining experience with a focus on traditional Korean cuisine.\n",
       "- **Link**: [Michelin Guide Seoul 2023](https://guide.michelin.com/sg/en/article/travel/5-new-michelin-starred-restaurants-in-seoul-en-2023-sg)\n",
       "\n",
       "For a more comprehensive list of dining options, you can also check out the following resources:\n",
       "- [Tripadvisor's Best Restaurants in Seoul](https://www.tripadvisor.com/Restaurants-g294197-Seoul.html)\n",
       "- [Eater's 38 Best Restaurants in Seoul](https://www.eater.com/maps/best-seoul-restaurants-38)\n",
       "\n",
       "These sources provide detailed reviews and additional dining options to explore in downtown Seoul. Enjoy your meal!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This question although does not contain instructions for a tool, the brain agent decides what tool to use\n",
    "printmd(brain_agent_executor.invoke({\"question\": \"What's a good place to dine today in downtown Seoul?\"}, config=config)[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c289a29-55c4-46df-b8a0-68d5674c1286",
   "metadata": {},
   "source": [
    "# Option 3: Using LangGraph\n",
    "See Notebook 11.5 (experimental)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a54fc7-ec9b-4ced-9e17-c65d00aa97f6",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c48d899-bd7b-4081-a656-e8d9e597220d",
   "metadata": {},
   "source": [
    "Great!, We just built the GPT Smart Search Engine!\n",
    "In this Notebook we created the brain, the decision making Agent that decides what Tool to use to answer the question from the user. This is what was necessary in order to have an smart chat bot.\n",
    "\n",
    "We can have many tools to accomplish different tasks, including connecting to APIs, dealing with File Systems, and even using Humans as Tools. For more reference see [HERE](https://python.langchain.com/docs/integrations/tools/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e99872-b01b-4e1a-9d41-04f70e22bbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
