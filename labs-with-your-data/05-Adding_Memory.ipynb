{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a8b5c0-87cb-4302-8e3c-dc809d0039fb",
   "metadata": {},
   "source": [
    "# Understanding Memory in LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f73380-6395-4e9f-9c83-3f47a5d7e292",
   "metadata": {},
   "source": [
    "In the previous Notebooks, we successfully explored how OpenAI models can enhance the results from Azure AI Search queries. \n",
    "\n",
    "However, we have yet to discover how to engage in a conversation with the LLM. With [Bing Chat](http://chat.bing.com/), for example, this is possible, as it can understand and reference the previous responses.\n",
    "\n",
    "There is a common misconception that LLMs (Large Language Models) have memory. This is not true. While they possess knowledge, they do not retain information from previous questions asked to them.\n",
    "\n",
    "In this Notebook, our goal is to illustrate how we can effectively \"endow the LLM with memory\" by employing prompts and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "733c782e-204c-47d0-8dae-c9df7091ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory, CosmosDBChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables import ConfigurableFieldSpec\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "from typing import List\n",
    "\n",
    "from IPython.display import Markdown, HTML, display  \n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "#custom libraries that we will use later in the app\n",
    "from common.utils import CustomAzureSearchRetriever, get_answer\n",
    "from common.prompts import DOCSEARCH_PROMPT\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials.env\")\n",
    "\n",
    "import logging\n",
    "\n",
    "# Get the root logger\n",
    "logger = logging.getLogger()\n",
    "# Set the logging level to a higher level to ignore INFO messages\n",
    "logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bc63c55-a57d-49a7-b6c7-0f18bca8199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc72b22-11c2-4df0-91b8-033d01829663",
   "metadata": {},
   "source": [
    "### Let's start with the basics\n",
    "Let's use a very simple example to see if the GPT model of Azure OpenAI have memory. We again will be using langchain to simplify our code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eef5dc9-8b80-4085-980c-865fa41fa1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"Tell me some use cases for reinforcement learning\"\n",
    "FOLLOW_UP_QUESTION = \"What was my prior question?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a00181d5-bd76-4ce4-a256-75ac5b58c60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETION_TOKENS = 1000\n",
    "# Create an OpenAI instance\n",
    "llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT35_DEPLOYMENT_NAME\"], \n",
    "                      temperature=0.5, max_tokens=COMPLETION_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9502d0f1-fddf-40d1-95d2-a1461dcc498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a very simple prompt template, just the question as is:\n",
    "output_parser = StrOutputParser()\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an assistant that give thorough responses to users.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5c9903e-15c7-4e05-87a1-58e5a7917ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Reinforcement learning is a type of machine learning that involves an agent learning to make decisions in an environment in order to maximize a reward. It has a wide range of use cases across various domains. Here are a few examples:\n",
       "\n",
       "1. Game playing: Reinforcement learning has been successfully applied to games like chess, Go, and poker, where the agent learns to make optimal moves and strategies by playing against itself or human opponents.\n",
       "\n",
       "2. Robotics: Reinforcement learning can be used to train robots to perform complex tasks, such as grasping objects, walking, or flying. The agent learns through trial and error, receiving rewards or penalties based on its actions.\n",
       "\n",
       "3. Autonomous vehicles: Reinforcement learning can help train self-driving cars to make decisions in real-time, such as navigating through traffic, following traffic rules, and avoiding accidents.\n",
       "\n",
       "4. Recommendation systems: Reinforcement learning can be used to personalize recommendations for users based on their preferences and feedback. The agent learns to optimize the recommendations by observing user behavior and feedback.\n",
       "\n",
       "5. Supply chain management: Reinforcement learning can optimize decision-making in supply chain management, such as inventory management, pricing, and demand forecasting, to maximize profitability and customer satisfaction.\n",
       "\n",
       "6. Healthcare: Reinforcement learning can assist in personalized treatment planning, drug dosage optimization, and clinical decision-making. The agent learns from patient data and medical guidelines to make informed decisions.\n",
       "\n",
       "7. Finance: Reinforcement learning can be used for algorithmic trading, portfolio management, and risk assessment. The agent learns to make trading decisions based on market conditions and historical data.\n",
       "\n",
       "8. Energy management: Reinforcement learning can optimize energy consumption and distribution in smart grids, helping to balance supply and demand, reduce costs, and improve efficiency.\n",
       "\n",
       "These are just a few examples, and the applications of reinforcement learning are continually expanding as researchers and practitioners explore its potential in various fields."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's see what the GPT model responds\n",
    "chain = prompt | llm | output_parser\n",
    "response_to_initial_question = chain.invoke({\"input\": QUESTION})\n",
    "display(Markdown(response_to_initial_question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99acaf3c-ce68-4b87-b24a-6065b15ff9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Your prior question was \"What was my prior question?\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Now let's ask a follow up question\n",
    "printmd(chain.invoke({\"input\": FOLLOW_UP_QUESTION}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e1c143-c95f-4566-a8b4-af8c42f08dd2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "As you can see, it doesn't remember what it just responded, sometimes it responds based only on the system prompt, or just randomly. This proof that the LLM does NOT have memory and that we need to give the memory as a a conversation history as part of the prompt, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0946ce71-6285-432e-b011-9c2dc1ba7b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"\n",
    "    {history}\n",
    "    Human: {question}\n",
    "    AI:\n",
    "\"\"\"\n",
    ")\n",
    "chain = hist_prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d088e51-e5eb-4143-b87d-b2be429eb864",
   "metadata": {},
   "outputs": [],
   "source": [
    "Conversation_history = \"\"\"\n",
    "Human: {question}\n",
    "AI: {response}\n",
    "\"\"\".format(question=QUESTION, response=response_to_initial_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d99e34ad-5539-44dd-b080-3ad05efd2f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Your prior question was \"Tell me some use cases for reinforcement learning.\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd(chain.invoke({\"history\":Conversation_history, \"question\": FOLLOW_UP_QUESTION}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045e5af6-55d6-4353-b3f6-3275c95db00a",
   "metadata": {},
   "source": [
    "**Bingo!**, so we now know how to create a chatbot using LLMs, we just need to keep the state/history of the conversation and pass it as context every time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafd1694-0077-4aa8-bd01-e9f763ce36a3",
   "metadata": {},
   "source": [
    "## Now that we understand the concept of memory via adding history as a context, let's go back to our GPT Smart Search engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9787ffb6-2b11-4b03-92fc-9443cd1f2ab9",
   "metadata": {},
   "source": [
    "From Langchain website:\n",
    "    \n",
    "A memory system needs to support two basic actions: reading and writing. Recall that every chain defines some core execution logic that expects certain inputs. Some of these inputs come directly from the user, but some of these inputs can come from memory. A chain will interact with its memory system twice in a given run.\n",
    "\n",
    "    AFTER receiving the initial user inputs but BEFORE executing the core logic, a chain will READ from its memory system and augment the user inputs.\n",
    "    AFTER executing the core logic but BEFORE returning the answer, a chain will WRITE the inputs and outputs of the current run to memory, so that they can be referred to in future runs.\n",
    "    \n",
    "So this process adds delays to the response, but it is a necessary delay :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36e8f14-e566-4ae9-a7d4-6dee7f469dad",
   "metadata": {},
   "source": [
    "![image](https://python.langchain.com/assets/images/memory_diagram-0627c68230aa438f9b5419064d63cbbc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef9f459b-e8b8-40b9-a94d-80c079968594",
   "metadata": {},
   "outputs": [],
   "source": [
    "index1_name = \"cogsrch-index-files\"\n",
    "index2_name = \"cogsrch-index-csv\"\n",
    "index3_name = \"cogsrch-index-books\"\n",
    "indexes = [index1_name, index2_name, index3_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d87cc7c6-5ef1-4492-b133-9f63a392e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the function to retrieve the conversation\n",
    "\n",
    "def get_session_history(session_id: str, user_id: str) -> CosmosDBChatMessageHistory:\n",
    "    cosmos = CosmosDBChatMessageHistory(\n",
    "        cosmos_endpoint=os.environ['AZURE_COSMOSDB_ENDPOINT'],\n",
    "        cosmos_database=os.environ['AZURE_COSMOSDB_NAME'],\n",
    "        cosmos_container=os.environ['AZURE_COSMOSDB_CONTAINER_NAME'],\n",
    "        connection_string=os.environ['AZURE_COMOSDB_CONNECTION_STRING'],\n",
    "        session_id=session_id,\n",
    "        user_id=user_id\n",
    "        )\n",
    "\n",
    "    # prepare the cosmosdb instance\n",
    "    cosmos.prepare_cosmos()\n",
    "    return cosmos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94f4179b-c1c7-49da-9c80-a42c275ed4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\",\n",
    "    history_factory_config=[\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"user_id\",\n",
    "            annotation=str,\n",
    "            name=\"User ID\",\n",
    "            description=\"Unique identifier for the user.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"session_id\",\n",
    "            annotation=str,\n",
    "            name=\"Session ID\",\n",
    "            description=\"Unique identifier for the conversation.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "    ],\n",
    ") | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cf1f1f0-6e46-4136-9f33-4e46617b7d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where we configure the session id and user id\n",
    "random_session_id = \"session\"+ str(random.randint(1, 1000))\n",
    "ramdom_user_id = \"user\"+ str(random.randint(1, 1000))\n",
    "\n",
    "config={\"configurable\": {\"session_id\": random_session_id, \"user_id\": ramdom_user_id}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b20c00c-4098-4970-84e5-f71ea7615c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'session_id': 'session996', 'user_id': 'user213'}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e3c32f4-f883-4045-91f9-ca317c2d01fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- Game playing: Reinforcement learning has been successfully applied to various games, such as chess, Go, and poker. It can learn optimal strategies and improve its performance through trial and error.\n",
       "- Robotics: Reinforcement learning can be used to train robots to perform complex tasks, such as grasping objects, walking, or flying. The robots can learn through interaction with the environment and receive rewards or penalties based on their actions.\n",
       "- Autonomous vehicles: Reinforcement learning can be used to train self-driving cars or drones. The vehicles can learn to navigate through traffic, make decisions, and avoid accidents by receiving rewards or penalties based on their actions.\n",
       "- Recommendation systems: Reinforcement learning can be used to personalize recommendations for users. It can learn from user feedback and adapt the recommendations to improve user satisfaction.\n",
       "- Resource management: Reinforcement learning can be used to optimize the allocation of resources in various domains, such as energy management, traffic control, or supply chain management. It can learn to make decisions that maximize efficiency and minimize costs.\n",
       "- Healthcare: Reinforcement learning can be used to optimize treatment plans for patients. It can learn from patient data and medical guidelines to make personalized recommendations for treatments.\n",
       "- Finance: Reinforcement learning can be used to optimize trading strategies in financial markets. It can learn to make decisions based on market data and maximize profits.\n",
       "- Advertising: Reinforcement learning can be used to optimize online advertising campaigns. It can learn from user interactions and feedback to improve targeting and increase conversion rates.\n",
       "- Control systems: Reinforcement learning can be used to optimize control systems in various domains, such as industrial processes, power grids, or smart buildings. It can learn to make decisions that optimize performance and energy efficiency.\n",
       "- Natural language processing: Reinforcement learning can be used to train dialogue systems or chatbots. It can learn to generate responses that maximize user satisfaction and engagement."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd(chain_with_history.invoke({\"question\": QUESTION}, config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e29643b-a531-4117-8e85-9c88a625cf02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Your prior question was \"Tell me some use cases for reinforcement learning\"."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remembers\n",
    "printmd(chain_with_history.invoke({\"question\": FOLLOW_UP_QUESTION},config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50146f05-5ef6-484f-a8ec-9631643054f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure! We discussed various use cases for reinforcement learning, including game playing, robotics, autonomous vehicles, recommendation systems, resource management, healthcare, finance, advertising, control systems, and natural language processing."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remembers\n",
    "printmd(chain_with_history.invoke(\n",
    "    {\"question\": \"Can you tell me a one line summary of our conversation?\"},\n",
    "    config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bc02369-904c-4063-93e1-fff24fe6a3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You're welcome! If you have any more questions, feel free to ask."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    printmd(chain_with_history.invoke(\n",
    "    {\"question\": \"Thank you very much!\"},\n",
    "    config=config))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc5ac98",
   "metadata": {},
   "source": [
    "#### Let's check our Azure CosmosDB to see the whole conversation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e30694-ae2a-47bb-a5c7-db51ecdbba1e",
   "metadata": {},
   "source": [
    "![CosmosDB Memory](./images/cosmos-chathistory.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6789cada-23a3-451a-a91a-0906ceb0bd14",
   "metadata": {},
   "source": [
    "# Summary\n",
    "##### Adding memory to our application allows the user to have a conversation, however this feature is not something that comes with the LLM, but instead, memory is something that we must provide to the LLM in form of context of the question.\n",
    "\n",
    "We added persitent memory using CosmosDB.\n",
    "\n",
    "We also can notice that the current chain that we are using is smart, but not that much. Although we have given memory to it, it searches for similar docs everytime, regardless of the input. This doesn't seem efficient, but regardless, we are very close to finish our first RAG-talk to your data Bot.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c629ebf4-aced-45b7-a6a2-315810d37d48",
   "metadata": {},
   "source": [
    "# NEXT\n",
    "We know now how to do a Smart Search Engine that can power a chatbot!! great!\n",
    "\n",
    "In the next notebook 6, we are going to build our first RAG bot. In order to do this we will introduce the concept of Agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53a8f7a-5e28-4d5f-9a33-0a3be0536b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
