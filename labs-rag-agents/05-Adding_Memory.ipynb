{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a8b5c0-87cb-4302-8e3c-dc809d0039fb",
   "metadata": {},
   "source": [
    "# Understanding Memory in LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f73380-6395-4e9f-9c83-3f47a5d7e292",
   "metadata": {},
   "source": [
    "In the previous Notebooks, we successfully explored how OpenAI models can enhance the results from Azure AI Search queries. \n",
    "\n",
    "However, we have yet to discover how to engage in a conversation with the LLM. With [Bing Chat](http://chat.bing.com/), for example, this is possible, as it can understand and reference the previous responses.\n",
    "\n",
    "There is a common misconception that LLMs (Large Language Models) have memory. This is not true. While they possess knowledge, they do not retain information from previous questions asked to them.\n",
    "\n",
    "In this Notebook, our goal is to illustrate how we can effectively \"endow the LLM with memory\" by employing prompts and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "733c782e-204c-47d0-8dae-c9df7091ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory, CosmosDBChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables import ConfigurableFieldSpec\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "from typing import List\n",
    "\n",
    "from IPython.display import Markdown, HTML, display  \n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "#custom libraries that we will use later in the app\n",
    "from common.utils import CustomAzureSearchRetriever, get_answer\n",
    "from common.prompts import DOCSEARCH_PROMPT\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials.env\")\n",
    "\n",
    "import logging\n",
    "\n",
    "# Get the root logger\n",
    "logger = logging.getLogger()\n",
    "# Set the logging level to a higher level to ignore INFO messages\n",
    "logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bc63c55-a57d-49a7-b6c7-0f18bca8199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc72b22-11c2-4df0-91b8-033d01829663",
   "metadata": {},
   "source": [
    "### Let's start with the basics\n",
    "Let's use a very simple example to see if the GPT model of Azure OpenAI have memory. We again will be using langchain to simplify our code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eef5dc9-8b80-4085-980c-865fa41fa1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"Tell me some use cases for reinforcement learning\"\n",
    "FOLLOW_UP_QUESTION = \"What was my prior question?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a00181d5-bd76-4ce4-a256-75ac5b58c60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETION_TOKENS = 1000\n",
    "# Create an OpenAI instance\n",
    "llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT4_DEPLOYMENT_NAME\"], \n",
    "                      temperature=0.5, max_tokens=COMPLETION_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9502d0f1-fddf-40d1-95d2-a1461dcc498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a very simple prompt template, just the question as is:\n",
    "output_parser = StrOutputParser()\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an assistant that give thorough responses to users.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5c9903e-15c7-4e05-87a1-58e5a7917ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Reinforcement learning (RL) is a type of machine learning where an agent learns to make decisions by performing certain actions and receiving rewards or penalties. This trial-and-error approach helps the agent to maximize cumulative reward over time. Here are some notable use cases across various domains:\n",
       "\n",
       "### 1. **Gaming and Entertainment**\n",
       "   - **Game Playing**: RL has been used to develop AI that can play games at superhuman levels. Notable examples include DeepMind's AlphaGo, which defeated world champions in the game of Go, and OpenAI's Dota 2 bots.\n",
       "   - **Game Development**: RL can be used to create non-player characters (NPCs) that learn and adapt to player behavior, making games more challenging and engaging.\n",
       "\n",
       "### 2. **Robotics**\n",
       "   - **Autonomous Navigation**: Robots can learn to navigate complex environments, such as warehouses or factories, avoiding obstacles and optimizing paths.\n",
       "   - **Manipulation Tasks**: RL can be used to teach robots to perform tasks like picking and placing objects, assembling products, or even cooking.\n",
       "\n",
       "### 3. **Healthcare**\n",
       "   - **Personalized Treatment Plans**: RL can help in developing personalized treatment strategies for patients by continuously learning from their responses to different treatments.\n",
       "   - **Medical Imaging**: RL can assist in optimizing the parameters for imaging devices to produce clearer images while minimizing exposure to harmful radiation.\n",
       "\n",
       "### 4. **Finance**\n",
       "   - **Algorithmic Trading**: RL algorithms can be used to develop trading strategies that learn to maximize returns by adapting to market conditions.\n",
       "   - **Portfolio Management**: RL can help in dynamically adjusting the composition of investment portfolios to maximize returns while managing risk.\n",
       "\n",
       "### 5. **Autonomous Vehicles**\n",
       "   - **Self-Driving Cars**: RL is used to train autonomous vehicles to make decisions in real-time, such as lane changing, obstacle avoidance, and route planning.\n",
       "   - **Traffic Management**: RL can be applied to optimize traffic light control systems to reduce congestion and improve traffic flow.\n",
       "\n",
       "### 6. **Natural Language Processing (NLP)**\n",
       "   - **Dialogue Systems**: RL can be used to train conversational agents to interact more naturally and effectively with users.\n",
       "   - **Machine Translation**: RL can improve translation systems by optimizing for fluency and accuracy over time.\n",
       "\n",
       "### 7. **Energy Management**\n",
       "   - **Smart Grids**: RL can optimize the distribution of electricity in smart grids, balancing supply and demand while minimizing costs.\n",
       "   - **Building Energy Management**: RL can be used to control heating, ventilation, and air conditioning (HVAC) systems to reduce energy consumption while maintaining comfort.\n",
       "\n",
       "### 8. **Industrial Automation**\n",
       "   - **Predictive Maintenance**: RL can predict equipment failures and optimize maintenance schedules to minimize downtime and costs.\n",
       "   - **Process Optimization**: RL can be used to optimize manufacturing processes, improving efficiency and reducing waste.\n",
       "\n",
       "### 9. **Marketing and Advertising**\n",
       "   - **Personalized Recommendations**: RL can be used to develop recommendation systems that adapt to user preferences over time, improving user engagement.\n",
       "   - **Ad Placement**: RL can optimize the placement and timing of advertisements to maximize click-through rates and conversions.\n",
       "\n",
       "### 10. **Resource Management**\n",
       "   - **Supply Chain Optimization**: RL can help in optimizing supply chain operations, including inventory management, logistics, and distribution.\n",
       "   - **Water Management**: RL can be used to optimize the distribution and usage of water resources in agriculture and urban settings.\n",
       "\n",
       "### 11. **Telecommunications**\n",
       "   - **Network Optimization**: RL can be used to optimize the performance of communication networks, improving data throughput and reducing latency.\n",
       "   - **Dynamic Spectrum Allocation**: RL can help in dynamically allocating radio frequencies to improve the efficiency of wireless communication systems.\n",
       "\n",
       "### 12. **Education**\n",
       "   - **Personalized Learning**: RL can be used to develop adaptive learning systems that tailor educational content to individual student needs, improving learning outcomes.\n",
       "   - **Tutoring Systems**: RL can be applied to create intelligent tutoring systems that provide personalized feedback and guidance to students.\n",
       "\n",
       "Reinforcement learning is a powerful tool with a wide range of applications, and its potential continues to grow as the technology advances."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's see what the GPT model responds\n",
    "chain = prompt | llm | output_parser\n",
    "response_to_initial_question = chain.invoke({\"input\": QUESTION})\n",
    "display(Markdown(response_to_initial_question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99acaf3c-ce68-4b87-b24a-6065b15ff9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I'm sorry, but I don't have access to prior interactions or any previous questions you may have asked. How can I assist you today?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Now let's ask a follow up question\n",
    "printmd(chain.invoke({\"input\": FOLLOW_UP_QUESTION}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e1c143-c95f-4566-a8b4-af8c42f08dd2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "As you can see, it doesn't remember what it just responded, sometimes it responds based only on the system prompt, or just randomly. This proof that the LLM does NOT have memory and that we need to give the memory as a a conversation history as part of the prompt, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0946ce71-6285-432e-b011-9c2dc1ba7b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"\n",
    "    {history}\n",
    "    Human: {question}\n",
    "    AI:\n",
    "\"\"\"\n",
    ")\n",
    "chain = hist_prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d088e51-e5eb-4143-b87d-b2be429eb864",
   "metadata": {},
   "outputs": [],
   "source": [
    "Conversation_history = \"\"\"\n",
    "Human: {question}\n",
    "AI: {response}\n",
    "\"\"\".format(question=QUESTION, response=response_to_initial_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d99e34ad-5539-44dd-b080-3ad05efd2f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Your prior question was: \"Tell me some use cases for reinforcement learning.\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd(chain.invoke({\"history\":Conversation_history, \"question\": FOLLOW_UP_QUESTION}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045e5af6-55d6-4353-b3f6-3275c95db00a",
   "metadata": {},
   "source": [
    "**Bingo!**, so we now know how to create a chatbot using LLMs, we just need to keep the state/history of the conversation and pass it as context every time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafd1694-0077-4aa8-bd01-e9f763ce36a3",
   "metadata": {},
   "source": [
    "## Now that we understand the concept of memory via adding history as a context, let's go back to our GPT Smart Search engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9787ffb6-2b11-4b03-92fc-9443cd1f2ab9",
   "metadata": {},
   "source": [
    "From Langchain website:\n",
    "    \n",
    "A memory system needs to support two basic actions: reading and writing. Recall that every chain defines some core execution logic that expects certain inputs. Some of these inputs come directly from the user, but some of these inputs can come from memory. A chain will interact with its memory system twice in a given run.\n",
    "\n",
    "    AFTER receiving the initial user inputs but BEFORE executing the core logic, a chain will READ from its memory system and augment the user inputs.\n",
    "    AFTER executing the core logic but BEFORE returning the answer, a chain will WRITE the inputs and outputs of the current run to memory, so that they can be referred to in future runs.\n",
    "    \n",
    "So this process adds delays to the response, but it is a necessary delay :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36e8f14-e566-4ae9-a7d4-6dee7f469dad",
   "metadata": {},
   "source": [
    "![image](https://python.langchain.com/assets/images/memory_diagram-0627c68230aa438f9b5419064d63cbbc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef9f459b-e8b8-40b9-a94d-80c079968594",
   "metadata": {},
   "outputs": [],
   "source": [
    "index1_name = \"cogsrch-index-files\"\n",
    "index2_name = \"cogsrch-index-csv\"\n",
    "index3_name = \"cogsrch-index-books\"\n",
    "indexes = [index1_name, index2_name, index3_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d87cc7c6-5ef1-4492-b133-9f63a392e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the function to retrieve the conversation\n",
    "\n",
    "def get_session_history(session_id: str, user_id: str) -> CosmosDBChatMessageHistory:\n",
    "    cosmos = CosmosDBChatMessageHistory(\n",
    "        cosmos_endpoint=os.environ['AZURE_COSMOSDB_ENDPOINT'],\n",
    "        cosmos_database=os.environ['AZURE_COSMOSDB_NAME'],\n",
    "        cosmos_container=os.environ['AZURE_COSMOSDB_CONTAINER_NAME'],\n",
    "        connection_string=os.environ['AZURE_COMOSDB_CONNECTION_STRING'],\n",
    "        session_id=session_id,\n",
    "        user_id=user_id\n",
    "        )\n",
    "\n",
    "    # prepare the cosmosdb instance\n",
    "    cosmos.prepare_cosmos()\n",
    "    return cosmos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94f4179b-c1c7-49da-9c80-a42c275ed4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\",\n",
    "    history_factory_config=[\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"user_id\",\n",
    "            annotation=str,\n",
    "            name=\"User ID\",\n",
    "            description=\"Unique identifier for the user.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"session_id\",\n",
    "            annotation=str,\n",
    "            name=\"Session ID\",\n",
    "            description=\"Unique identifier for the conversation.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "    ],\n",
    ") | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cf1f1f0-6e46-4136-9f33-4e46617b7d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where we configure the session id and user id\n",
    "random_session_id = \"session\"+ str(random.randint(1, 1000))\n",
    "ramdom_user_id = \"user\"+ str(random.randint(1, 1000))\n",
    "\n",
    "config={\"configurable\": {\"session_id\": random_session_id, \"user_id\": ramdom_user_id}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b20c00c-4098-4970-84e5-f71ea7615c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'session_id': 'session834', 'user_id': 'user733'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e3c32f4-f883-4045-91f9-ca317c2d01fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Reinforcement learning (RL) is a type of machine learning where an agent learns to make decisions by performing actions in an environment to maximize some notion of cumulative reward. Here are several use cases for reinforcement learning:\n",
       "\n",
       "1. **Robotics**:\n",
       "   - **Autonomous Navigation**: RL can be used to train robots to navigate through complex environments without human intervention.\n",
       "   - **Manipulation Tasks**: Robots can learn to perform tasks like picking and placing objects, assembling parts, or even cooking.\n",
       "\n",
       "2. **Gaming**:\n",
       "   - **Game Playing**: RL has been used to develop agents that can play games at superhuman levels, such as AlphaGo for the game of Go, and OpenAI Five for Dota 2.\n",
       "   - **Game Testing**: RL can automate the process of testing video games by simulating human-like play.\n",
       "\n",
       "3. **Finance**:\n",
       "   - **Algorithmic Trading**: RL can optimize trading strategies to maximize returns while managing risk.\n",
       "   - **Portfolio Management**: It can be used to dynamically adjust the composition of a portfolio to achieve the best performance.\n",
       "\n",
       "4. **Healthcare**:\n",
       "   - **Treatment Planning**: RL can help in creating personalized treatment plans for patients by considering the long-term effects of various treatments.\n",
       "   - **Medical Imaging**: It can improve the accuracy of diagnostics by optimizing the parameters used in imaging techniques.\n",
       "\n",
       "5. **Autonomous Vehicles**:\n",
       "   - **Self-Driving Cars**: RL can be used to train autonomous vehicles to navigate safely and efficiently in various driving conditions.\n",
       "   - **Traffic Management**: RL can optimize traffic light control systems to reduce congestion and improve traffic flow.\n",
       "\n",
       "6. **Energy Management**:\n",
       "   - **Smart Grid Optimization**: RL can be used to balance supply and demand in smart grids, optimizing energy distribution.\n",
       "   - **Energy Consumption**: It can help in reducing energy consumption in buildings by optimizing heating, ventilation, and air conditioning (HVAC) systems.\n",
       "\n",
       "7. **Natural Language Processing**:\n",
       "   - **Dialogue Systems**: RL can improve the performance of chatbots and virtual assistants by optimizing their responses to user queries.\n",
       "   - **Machine Translation**: It can enhance the accuracy and fluency of machine translation systems.\n",
       "\n",
       "8. **Manufacturing**:\n",
       "   - **Process Optimization**: RL can optimize manufacturing processes to improve efficiency and reduce waste.\n",
       "   - **Predictive Maintenance**: It can predict equipment failures and schedule maintenance to minimize downtime.\n",
       "\n",
       "9. **Marketing**:\n",
       "   - **Personalized Recommendations**: RL can enhance recommendation systems by tailoring suggestions to individual user preferences.\n",
       "   - **Ad Placement**: It can optimize the placement of advertisements to maximize click-through rates and conversions.\n",
       "\n",
       "10. **Telecommunications**:\n",
       "    - **Network Optimization**: RL can optimize the allocation of resources in communication networks to improve performance and reduce latency.\n",
       "    - **Dynamic Spectrum Management**: It can be used to dynamically allocate spectrum resources to improve the efficiency of wireless communication.\n",
       "\n",
       "These are just a few examples, and the potential applications of reinforcement learning are vast and continually expanding as the technology advances."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd(chain_with_history.invoke({\"question\": QUESTION}, config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e29643b-a531-4117-8e85-9c88a625cf02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Your prior question was: \"Tell me some use cases for reinforcement learning.\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remembers\n",
    "printmd(chain_with_history.invoke({\"question\": FOLLOW_UP_QUESTION},config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50146f05-5ef6-484f-a8ec-9631643054f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You asked for use cases of reinforcement learning, and I provided a detailed list of various applications across different domains."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remembers\n",
    "printmd(chain_with_history.invoke(\n",
    "    {\"question\": \"Can you tell me a one line summary of our conversation?\"},\n",
    "    config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bc02369-904c-4063-93e1-fff24fe6a3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You're welcome! If you have any more questions or need further assistance, feel free to ask. Have a great day!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    printmd(chain_with_history.invoke(\n",
    "    {\"question\": \"Thank you very much!\"},\n",
    "    config=config))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc5ac98",
   "metadata": {},
   "source": [
    "#### Let's check our Azure CosmosDB to see the whole conversation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e30694-ae2a-47bb-a5c7-db51ecdbba1e",
   "metadata": {},
   "source": [
    "![CosmosDB Memory](./images/cosmos-chathistory.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6789cada-23a3-451a-a91a-0906ceb0bd14",
   "metadata": {},
   "source": [
    "# Summary\n",
    "##### Adding memory to our application allows the user to have a conversation, however this feature is not something that comes with the LLM, but instead, memory is something that we must provide to the LLM in form of context of the question.\n",
    "\n",
    "We added persitent memory using CosmosDB.\n",
    "\n",
    "We also can notice that the current chain that we are using is smart, but not that much. Although we have given memory to it, it searches for similar docs everytime, regardless of the input. This doesn't seem efficient, but regardless, we are very close to finish our first RAG-talk to your data Bot.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c629ebf4-aced-45b7-a6a2-315810d37d48",
   "metadata": {},
   "source": [
    "# NEXT\n",
    "We know now how to do a Smart Search Engine that can power a chatbot!! great!\n",
    "\n",
    "In the next notebook 6, we are going to build our first RAG bot. In order to do this we will introduce the concept of Agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53a8f7a-5e28-4d5f-9a33-0a3be0536b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
