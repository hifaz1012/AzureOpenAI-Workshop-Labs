{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44ad5da8",
   "metadata": {},
   "source": [
    "## Fine-Tuning GPT Models - A Python SDK Experience\n",
    "\n",
    "Learn how to fine-tune the <code>gpt-35-turbo-0613</code> model using Python Programming Language - An SDK / Code Experience. This notebook is based on the MS Learn tutorial [here](https://learn.microsoft.com/en-us/azure/ai-services/openai/tutorials/fine-tune?tabs=python%2Cbash).\n",
    "\n",
    "He Zhang, Feb. 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a270ee2",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "* Learn the [what, why, and when to use fine-tuning.](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/fine-tuning-considerations)\n",
    "* An Azure subscription.\n",
    "* Access to Azure OpenAI Service.\n",
    "* An Azure OpenAI resource created in the supported fine-tuning region (e.g. Sweden Central).\n",
    "* Prepare Training and Validation datasets:\n",
    "  * at least 50 high-quality samples (preferably 1,000s) are required.\n",
    "  * must be formatted in the JSON Lines (JSONL) document with UTF-8 encoding.\n",
    "  * for this test notebook, we use only 10 samples for the demo purpose. \n",
    "* Python version at least: <code>3.7.1</code>\n",
    "* Python libraries: <code>json, requests, os, tiktoken, time, python-dotenv, numpy, openai</code>\n",
    "* The OpenAI Python library version for this test notebook: <code>0.28.1</code>\n",
    "* [Jupyter Notebooks](https://jupyter.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699f837b",
   "metadata": {},
   "source": [
    "### Step 1: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd759f8f",
   "metadata": {},
   "source": [
    "#### Retrieve the Azure OpenAI API key and endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399a4647",
   "metadata": {},
   "source": [
    "Go to your resource in the Azure portal. The Endpoint and Keys can be found in the Resource Management section Go to your resource in the Azure portal.  \n",
    "<img src=\"../../images/screenshot-aoai-keys-and-endpoint.png\" alt=\"Screenshot of the Azure OpenAI resource management pane.\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f3b044",
   "metadata": {},
   "source": [
    "#### Configure credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd153223",
   "metadata": {},
   "source": [
    "Copy the <code>Endpoint</code> and access <code>KEY</code> (you can use either <code>KEY 1</code> or <code>KEY 2</code>), and paste them accordingly to the variables in the file <code>azure.env</code>. Save the file and close it. **Do not** distribute this file as this contains credential information! \n",
    "<img src=\"../../images/screenshot-azure-env-file.png\" alt=\"Screenshot of the azure.env file that contains credential information - do not show it to others!\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4574dc",
   "metadata": {},
   "source": [
    "#### Install required Python libraries (if not done yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c445eac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28.1 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (0.28.1)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from openai==0.28.1) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from openai==0.28.1) (4.66.4)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from openai==0.28.1) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from requests>=2.20->openai==0.28.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from requests>=2.20->openai==0.28.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from requests>=2.20->openai==0.28.1) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from requests>=2.20->openai==0.28.1) (2024.7.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from aiohttp->openai==0.28.1) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from aiohttp->openai==0.28.1) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from aiohttp->openai==0.28.1) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from aiohttp->openai==0.28.1) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from aiohttp->openai==0.28.1) (1.9.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from tqdm->openai==0.28.1) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tiktoken in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from tiktoken) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai==0.28.1  \n",
    "%pip install tiktoken\n",
    "%pip install numpy\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57d703e",
   "metadata": {},
   "source": [
    "#### Import required Python libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "229febe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import openai\n",
    "import requests\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbebe593",
   "metadata": {},
   "source": [
    "#### Load Azure OpenAI credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6b7a343",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"azure.env\")\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai.api_version = \"2023-12-01-preview\" # This API version or later is required to access fine-tuning for turbo/babbage-002/davinci-002"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfdf556",
   "metadata": {},
   "source": [
    "### Step 2: Prepare Training & Validation Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bed57b",
   "metadata": {},
   "source": [
    "#### The training and validation datasets have been made ready for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e4e564",
   "metadata": {},
   "source": [
    "<code>training_set.jsonl</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72662b27",
   "metadata": {},
   "source": [
    "```yaml\n",
    "{\"messages\": \n",
    "    [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, \n",
    "     {\"role\": \"user\", \"content\": \"Who discovered Antarctica?\"}, \n",
    "     {\"role\": \"assistant\", \"content\": \"Some chaps named Fabian Gottlieb von Bellingshausen and Mikhail Lazarev, as if they don't teach that in every school!\"}]}\n",
    "\n",
    "{\"messages\": \n",
    "    [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"},\n",
    "     {\"role\": \"user\", \"content\": \"What is the biggest ocean?\"}, \n",
    "     {\"role\": \"assistant\", \"content\": \"The Pacific Ocean. It's not like it's a small pond or anything.\"}]}\n",
    "\n",
    "{\"messages\": ...}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e3b290",
   "metadata": {},
   "source": [
    "<code>validation_set.jsonl</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956ff181",
   "metadata": {},
   "source": [
    "```yaml\n",
    "{\"messages\": \n",
    "    [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, \n",
    "     {\"role\": \"user\", \"content\": \"What's the capital of Australia?\"}, \n",
    "     {\"role\": \"assistant\", \"content\": \"It's Canberra, not Sydney. Shocking, I know!\"}]}\n",
    "\n",
    "{\"messages\": \n",
    "    [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"},\n",
    "     {\"role\": \"user\", \"content\": \"Who wrote 'The Great Gatsby'?\"}, \n",
    "     {\"role\": \"assistant\", \"content\": \"Some guy named F. Scott Fitzgerald. Ever heard of him?\"}]}\n",
    "     \n",
    "{\"messages\": ...}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19b30e0",
   "metadata": {},
   "source": [
    "#### Do initial checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfca565a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in training set: 10\n",
      "First example in training set:\n",
      "{'role': 'system', 'content': 'Clippy is a factual chatbot that is also sarcastic.'}\n",
      "{'role': 'user', 'content': 'Who discovered Antarctica?'}\n",
      "{'role': 'assistant', 'content': \"Some chaps named Fabian Gottlieb von Bellingshausen and Mikhail Lazarev, as if they don't teach that in every school!\"}\n"
     ]
    }
   ],
   "source": [
    "# Load the training set\n",
    "with open(\"./data/training_set.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    training_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Training dataset stats\n",
    "print(\"Number of examples in training set:\", len(training_dataset))\n",
    "print(\"First example in training set:\")\n",
    "for message in training_dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "007634ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of examples in validation set: 10\n",
      "First example in validation set:\n",
      "{'role': 'system', 'content': 'Clippy is a factual chatbot that is also sarcastic.'}\n",
      "{'role': 'user', 'content': \"What's the capital of Australia?\"}\n",
      "{'role': 'assistant', 'content': \"It's Canberra, not Sydney. Shocking, I know!\"}\n"
     ]
    }
   ],
   "source": [
    "# Load the validation set\n",
    "with open(\"./data/validation_set.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    validation_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Validation dataset stats\n",
    "print(\"\\nNumber of examples in validation set:\", len(validation_dataset))\n",
    "print(\"First example in validation set:\")\n",
    "for message in validation_dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114c83d3",
   "metadata": {},
   "source": [
    "### Step 3: Upload Datasets for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f54a4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file ID: file-5c8ea20003e84975a4ce476e9e9d5dad\n",
      "Validation file ID: file-b85d8503ca544b2596051eab630fc525\n"
     ]
    }
   ],
   "source": [
    "# Upload the training and validation dataset files to Azure OpenAI with the SDK.\n",
    "training_file_name = \"./data/training_set.jsonl\"\n",
    "validation_file_name = \"./data/validation_set.jsonl\"\n",
    "\n",
    "training_response = openai.File.create(\n",
    "    file=open(training_file_name, \"rb\"), \n",
    "    purpose=\"fine-tune\", \n",
    "    user_provided_filename=training_file_name\n",
    ")\n",
    "training_file_id = training_response[\"id\"]\n",
    "\n",
    "validation_response = openai.File.create(\n",
    "    file=open(validation_file_name, \"rb\"), \n",
    "    purpose=\"fine-tune\", \n",
    "    user_provided_filename=validation_file_name\n",
    ")\n",
    "validation_file_id = validation_response[\"id\"]\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aee27a",
   "metadata": {},
   "source": [
    "### Step 4: Begin Fine-Tuning Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a927f0c4",
   "metadata": {},
   "source": [
    "Now you can submit your fine-tuning training job. \n",
    "\n",
    "The fine-tuning job will take some time to start and complete.\n",
    "\n",
    "You can use the job ID to monitor the status of the fine-tuning job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e925985b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-1e450650d6b34aaeac7d7d55c6b94f3e\n",
      "Status: pending\n",
      "{\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": -1,\n",
      "    \"batch_size\": -1,\n",
      "    \"learning_rate_multiplier\": 1\n",
      "  },\n",
      "  \"status\": \"pending\",\n",
      "  \"model\": \"gpt-35-turbo-0613\",\n",
      "  \"training_file\": \"file-5c8ea20003e84975a4ce476e9e9d5dad\",\n",
      "  \"validation_file\": \"file-b85d8503ca544b2596051eab630fc525\",\n",
      "  \"id\": \"ftjob-1e450650d6b34aaeac7d7d55c6b94f3e\",\n",
      "  \"created_at\": 1721200845,\n",
      "  \"updated_at\": 1721200845,\n",
      "  \"object\": \"fine_tuning.job\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.FineTuningJob.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=\"gpt-35-turbo-0613\", # must be exactly this name\n",
    ")\n",
    "\n",
    "job_id = response[\"id\"]\n",
    "\n",
    "print(\"Job ID:\", response[\"id\"])\n",
    "print(\"Status:\", response[\"status\"])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa608e2f",
   "metadata": {},
   "source": [
    "### Step 5: Track Fine-Tuning Job Status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a5ad52",
   "metadata": {},
   "source": [
    "You can track the training job status by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa4b5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "# Track fine-tuning job training status\n",
    "start_time = time.time()\n",
    "\n",
    "# Get the status of our fine-tuning job.\n",
    "response = openai.FineTuningJob.retrieve(job_id)\n",
    "\n",
    "status = response[\"status\"]\n",
    "\n",
    "# If the job isn't done yet, poll it every 10 seconds.\n",
    "while status not in [\"succeeded\", \"failed\"]:\n",
    "    time.sleep(10)\n",
    "    \n",
    "    response = openai.FineTuningJob.retrieve(job_id)\n",
    "    print(response)\n",
    "    print(\"Elapsed time: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\n",
    "    status = response[\"status\"]\n",
    "    print(f\"Status: {status}\")\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print(f\"Fine-tuning job {job_id} finished with status: {status}\")\n",
    "\n",
    "# List all fine-tuning jobs for this resource.\n",
    "print(\"Checking other fine-tune jobs for this resource.\")\n",
    "response = openai.FineTuningJob.list()\n",
    "print(f'Found {len(response[\"data\"])} fine-tune jobs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afeb619",
   "metadata": {},
   "source": [
    "To get the full results, you can run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f1d03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve fine_tuned_model name\n",
    "response = openai.FineTuningJob.retrieve(job_id)\n",
    "print(response)\n",
    "\n",
    "fine_tuned_model = response[\"fine_tuned_model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a58b85",
   "metadata": {},
   "source": [
    "### Step 6: Deploy The Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370097d4",
   "metadata": {},
   "source": [
    "Model deployment must be done using the [REST API](https://learn.microsoft.com/en-us/rest/api/cognitiveservices/accountmanagement/deployments/create-or-update?view=rest-cognitiveservices-accountmanagement-2023-05-01&tabs=HTTP), which requires separate authorization, a different API path, and a different API version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53296c51",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>variable</th>\n",
    "<th>Definition</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>token</td>\n",
    "<td>There are multiple ways to generate an authorization token. The easiest method for initial testing is to launch the Cloud Shell from the <a href=\"https://portal.azure.com\" data-linktype=\"external\">Azure portal</a>. Then run <a href=\"/en-us/cli/azure/account#az-account-get-access-token()\" data-linktype=\"absolute-path\"><code>az account get-access-token</code></a>. You can use this token as your temporary authorization token for API testing. We recommend storing this in a new environment variable</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>subscription</td>\n",
    "<td>The subscription ID for the associated Azure OpenAI resource</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>resource_group</td>\n",
    "<td>The resource group name for your Azure OpenAI resource</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>resource_name</td>\n",
    "<td>The Azure OpenAI resource name</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>model_deployment_name</td>\n",
    "<td>The custom name for your new fine-tuned model deployment. This is the name that will be referenced in your code when making chat completion calls.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>fine_tuned_model</td>\n",
    "<td>Retrieve this value from your fine-tuning job results in the previous step. It will look like <code>gpt-35-turbo-0613.ft-b044a9d3cf9c4228b5d393567f693b83</code>. You will need to add that value to the deploy_data json.</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3848e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "token= os.getenv(\"TEMP_AUTH_TOKEN\") \n",
    "subscription = \"<YOUR_SUBSCRIPTION_ID>\"  \n",
    "resource_group = \"<YOUR_RESOURCE_GROUP_NAME>\"\n",
    "resource_name = \"<YOUR_AZURE_OPENAI_RESOURCE_NAME>\"\n",
    "model_deployment_name =\"YOUR_CUSTOM_MODEL_DEPLOYMENT_NAME\" \n",
    "\n",
    "deploy_params = {\"api-version\": \"2023-05-01\"} \n",
    "deploy_headers = {\"Authorization\": \"Bearer {}\".format(token), \"Content-Type\": \"application/json\"}\n",
    "deploy_data = {\n",
    "    \"sku\": {\"name\": \"standard\", \"capacity\": 1}, \n",
    "    \"properties\": {\n",
    "        \"model\": {\n",
    "            \"format\": \"OpenAI\",\n",
    "            \"name\": \"<YOUR_FINE_TUNED_MODEL>\", #retrieve this value from the previous call, it will look like gpt-35-turbo-0613.ft-b044a9d3cf9c4228b5d393567f693b83\n",
    "            \"version\": \"1\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "deploy_data = json.dumps(deploy_data)\n",
    "\n",
    "print(\"Creating a new deployment...\")\n",
    "request_url = f\"https://management.azure.com/subscriptions/{subscription}/resourceGroups/{resource_group}/providers/Microsoft.CognitiveServices/accounts/{resource_name}/deployments/{model_deployment_name}\"\n",
    "r = requests.put(request_url, params=deploy_params, headers=deploy_headers, data=deploy_data)\n",
    "\n",
    "print(r)\n",
    "print(r.reason)\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3404f0a0",
   "metadata": {},
   "source": [
    "You can check on your deployment progress in the Azure OpenAI Studio:\n",
    "\n",
    "<img src=\"../../images/screenshot-deployed-fine-tuned-model-via-sdk.png\" alt=\"Screenshot of the Azure OpenAI Studio - showing the model deployment status.\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefe6e0b",
   "metadata": {},
   "source": [
    "### Step 7: Test And Use The Deployed Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9e5bbc",
   "metadata": {},
   "source": [
    "After your fine-tuned model is deployed, you can use it like any other deployed model in either the [Chat Playground of Azure OpenAI Studio](https://oai.azure.com/), or via the chat completion API. \n",
    "\n",
    "For example, you can send a chat completion call to your deployed model, as shown in the following Python code snippet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e4cef4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"The capital of Malaysia is Kuala Lumpur.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1721201939,\n",
      "  \"id\": \"chatcmpl-9ltXXridBt6kkFPiGefDssQBU3KuR\",\n",
      "  \"model\": \"gpt-35-turbo-1106.ft-5d12e820c0a04a8bab7f2658b9ae7db8--finetune\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": \"fp_56b453fc06\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 8,\n",
      "    \"prompt_tokens\": 13,\n",
      "    \"total_tokens\": 21\n",
      "  }\n",
      "}\n",
      "The capital of Malaysia is Kuala Lumpur.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\") \n",
    "openai.api_version = \"2023-05-15\"\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    engine=\"gpt-35-turbo-finetune\", # engine = \"Custom deployment name you chose for your fine-tuning model\"\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is capital of Malaysia?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response)\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65563bf0",
   "metadata": {},
   "source": [
    "### Step 8: Delete The Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb666e8",
   "metadata": {},
   "source": [
    "It is **strongly recommended** that once you're done with this tutorial and have tested a few chat completion calls against your fine-tuned model, that you delete the model deployment, since the fine-tuned / customized models have an [hourly hosting cost](https://azure.microsoft.com/zh-cn/pricing/details/cognitive-services/openai-service/#pricing) associated with them once they are deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c328ad63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd8326f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
