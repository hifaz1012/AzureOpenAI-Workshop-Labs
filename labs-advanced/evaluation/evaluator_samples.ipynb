{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting promptflow-evals\n",
      "  Using cached promptflow_evals-0.3.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting aiohttp_retry>=2.8.3 (from promptflow-evals)\n",
      "  Using cached aiohttp_retry-2.8.3-py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: azure-core>=1.30.2 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from promptflow-evals) (1.30.2)\n",
      "Collecting azure-identity>=1.17.1 (from promptflow-evals)\n",
      "  Using cached azure_identity-1.17.1-py3-none-any.whl.metadata (79 kB)\n",
      "Collecting isort<6.0.0,>=5.13.2 (from promptflow-evals)\n",
      "  Using cached isort-5.13.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting jsonpath_ng>=1.5.0 (from promptflow-evals)\n",
      "  Using cached jsonpath_ng-1.6.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.22 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from promptflow-evals) (1.26.4)\n",
      "Collecting promptflow-core<2.0.0,>=1.14.0 (from promptflow-evals)\n",
      "  Using cached promptflow_core-1.15.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting promptflow-devkit<2.0.0,>=1.14.0 (from promptflow-evals)\n",
      "  Using cached promptflow_devkit-1.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: pyjwt>=2.8.0 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from promptflow-evals) (2.9.0)\n",
      "Requirement already satisfied: urllib3>1.26.17 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from promptflow-evals) (1.26.19)\n",
      "Collecting websocket-client>=1.2.0 (from promptflow-evals)\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from aiohttp_retry>=2.8.3->promptflow-evals) (3.9.5)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from azure-core>=1.30.2->promptflow-evals) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from azure-core>=1.30.2->promptflow-evals) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from azure-core>=1.30.2->promptflow-evals) (4.12.2)\n",
      "Requirement already satisfied: cryptography>=2.5 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from azure-identity>=1.17.1->promptflow-evals) (43.0.0)\n",
      "Requirement already satisfied: msal>=1.24.0 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from azure-identity>=1.17.1->promptflow-evals) (1.30.0)\n",
      "Collecting msal-extensions>=0.3.0 (from azure-identity>=1.17.1->promptflow-evals)\n",
      "  Using cached msal_extensions-1.2.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting ply (from jsonpath_ng>=1.5.0->promptflow-evals)\n",
      "  Using cached ply-3.11-py2.py3-none-any.whl.metadata (844 bytes)\n",
      "Collecting docstring_parser (from promptflow-core<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: fastapi<1.0.0,>=0.109.0 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from promptflow-core<2.0.0,>=1.14.0->promptflow-evals) (0.112.2)\n",
      "Collecting filetype>=1.2.0 (from promptflow-core<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting flask<4.0.0,>=2.2.3 (from promptflow-core<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from promptflow-core<2.0.0,>=1.14.0->promptflow-evals) (4.23.0)\n",
      "Collecting promptflow-tracing==1.15.0 (from promptflow-core<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached promptflow_tracing-1.15.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from promptflow-core<2.0.0,>=1.14.0->promptflow-evals) (6.0.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1.0 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from promptflow-core<2.0.0,>=1.14.0->promptflow-evals) (2.9.0.post0)\n",
      "Collecting ruamel.yaml<1.0.0,>=0.17.10 (from promptflow-core<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached ruamel.yaml-0.18.6-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: openai in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from promptflow-tracing==1.15.0->promptflow-core<2.0.0,>=1.14.0->promptflow-evals) (1.42.0)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.22.0 (from promptflow-tracing==1.15.0->promptflow-core<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached opentelemetry_sdk-1.26.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tiktoken>=0.4.0 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from promptflow-tracing==1.15.0->promptflow-core<2.0.0,>=1.14.0->promptflow-evals) (0.7.0)\n",
      "Collecting argcomplete>=3.2.3 (from promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached argcomplete-3.5.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21 (from promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached azure_monitor_opentelemetry_exporter-1.0.0b28-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals) (0.4.6)\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.4.0 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals) (3.15.4)\n",
      "Collecting flask-cors<5.0.0,>=4.0.0 (from promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached Flask_Cors-4.0.1-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting flask-restx<2.0.0,>=1.2.0 (from promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached flask_restx-1.3.0-py2.py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: gitpython<4.0.0,>=3.1.24 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals) (3.1.43)\n",
      "Requirement already satisfied: httpx>=0.25.1 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals) (0.27.2)\n",
      "Collecting keyring<25.0.0,>=24.2.0 (from promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached keyring-24.3.1-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.5 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals) (3.22.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 (from promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_http-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.5.3 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals) (2.2.2)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.1.0 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals) (10.4.0)\n",
      "Collecting pydash<8.0.0,>=6.0.0 (from promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached pydash-7.0.7-py3-none-any.whl.metadata (45 kB)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals) (1.0.1)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals) (306)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.48 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals) (2.0.32)\n",
      "Collecting strictyaml<2.0.0,>=1.5.0 (from promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached strictyaml-1.7.3-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: tabulate<1.0.0,>=0.9.0 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals) (0.9.0)\n",
      "Collecting waitress<3.0.0,>=2.1.2 (from promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached waitress-2.1.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting fixedint==0.1.6 (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached fixedint-0.1.6-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: msrest>=0.6.10 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals) (0.7.1)\n",
      "Collecting opentelemetry-api~=1.26 (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached opentelemetry_api-1.26.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting psutil (from promptflow-core<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached psutil-5.9.8-cp37-abi3-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from cryptography>=2.5->azure-identity>=1.17.1->promptflow-evals) (1.17.0)\n",
      "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core<2.0.0,>=1.14.0->promptflow-evals) (0.38.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core<2.0.0,>=1.14.0->promptflow-evals) (1.10.13)\n",
      "Collecting Werkzeug>=3.0.0 (from flask<4.0.0,>=2.2.3->promptflow-core<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Downloading werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow-core<2.0.0,>=1.14.0->promptflow-evals) (3.1.4)\n",
      "Collecting itsdangerous>=2.1.2 (from flask<4.0.0,>=2.2.3->promptflow-core<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow-core<2.0.0,>=1.14.0->promptflow-evals) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow-core<2.0.0,>=1.14.0->promptflow-evals) (1.8.2)\n",
      "Collecting aniso8601>=0.82 (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached aniso8601-9.0.1-py2.py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: pytz in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals) (2024.1)\n",
      "Collecting importlib-resources (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Downloading importlib_resources-6.4.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from gitpython<4.0.0,>=3.1.24->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals) (4.0.11)\n",
      "Requirement already satisfied: anyio in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from httpx>=0.25.1->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals) (4.4.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from httpx>=0.25.1->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from httpx>=0.25.1->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from httpx>=0.25.1->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals) (3.8)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from httpx>=0.25.1->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.1->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals) (0.14.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core<2.0.0,>=1.14.0->promptflow-evals) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core<2.0.0,>=1.14.0->promptflow-evals) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core<2.0.0,>=1.14.0->promptflow-evals) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core<2.0.0,>=1.14.0->promptflow-evals) (0.20.0)\n",
      "Collecting jaraco.classes (from keyring<25.0.0,>=24.2.0->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached jaraco.classes-3.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting importlib-metadata>=4.11.4 (from keyring<25.0.0,>=24.2.0->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Downloading importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting pywin32-ctypes>=0.2.0 (from keyring<25.0.0,>=24.2.0->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached pywin32_ctypes-0.2.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.5->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals) (24.1)\n",
      "Collecting portalocker<3,>=1.4 (from msal-extensions>=0.3.0->azure-identity>=1.17.1->promptflow-evals)\n",
      "  Using cached portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.26.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.26.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached opentelemetry_proto-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting protobuf<5.0,>=3.19 (from opentelemetry-proto==1.26.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached protobuf-4.25.4-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from pandas<3.0.0,>=1.5.3->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.2->promptflow-evals) (3.3.2)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml<1.0.0,>=0.17.10->promptflow-core<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached ruamel.yaml.clib-0.2.8-cp311-cp311-win_amd64.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from sqlalchemy<3.0.0,>=1.4.48->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals) (3.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from aiohttp->aiohttp_retry>=2.8.3->promptflow-evals) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from aiohttp->aiohttp_retry>=2.8.3->promptflow-evals) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from aiohttp->aiohttp_retry>=2.8.3->promptflow-evals) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from aiohttp->aiohttp_retry>=2.8.3->promptflow-evals) (1.9.4)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity>=1.17.1->promptflow-evals) (2.22)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.6->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached wrapt-1.16.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.24->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals) (5.0.1)\n",
      "Collecting zipp>=0.5 (from importlib-metadata>=4.11.4->keyring<25.0.0,>=24.2.0->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Downloading zipp-3.20.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from Jinja2>=3.1.2->flask<4.0.0,>=2.2.3->promptflow-core<2.0.0,>=1.14.0->promptflow-evals) (2.1.5)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from msrest>=0.6.10->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals) (0.6.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from msrest>=0.6.10->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals) (2.0.0)\n",
      "Collecting importlib-metadata>=4.11.4 (from keyring<25.0.0,>=24.2.0->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached importlib_metadata-8.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.47b0 (from opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.15.0->promptflow-core<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from tiktoken>=0.4.0->promptflow-tracing==1.15.0->promptflow-core<2.0.0,>=1.14.0->promptflow-evals) (2024.7.24)\n",
      "Collecting more-itertools (from jaraco.classes->keyring<25.0.0,>=24.2.0->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals)\n",
      "  Using cached more_itertools-10.4.0-py3-none-any.whl.metadata (36 kB)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from openai->promptflow-tracing==1.15.0->promptflow-core<2.0.0,>=1.14.0->promptflow-evals) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from openai->promptflow-tracing==1.15.0->promptflow-core<2.0.0,>=1.14.0->promptflow-evals) (0.5.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from openai->promptflow-tracing==1.15.0->promptflow-core<2.0.0,>=1.14.0->promptflow-evals) (4.66.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.10->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit<2.0.0,>=1.14.0->promptflow-evals) (3.2.2)\n",
      "Using cached promptflow_evals-0.3.2-py3-none-any.whl (113 kB)\n",
      "Using cached aiohttp_retry-2.8.3-py3-none-any.whl (9.8 kB)\n",
      "Using cached azure_identity-1.17.1-py3-none-any.whl (173 kB)\n",
      "Using cached isort-5.13.2-py3-none-any.whl (92 kB)\n",
      "Using cached jsonpath_ng-1.6.1-py3-none-any.whl (29 kB)\n",
      "Using cached promptflow_core-1.15.0-py3-none-any.whl (987 kB)\n",
      "Using cached promptflow_tracing-1.15.0-py3-none-any.whl (26 kB)\n",
      "Using cached promptflow_devkit-1.15.0-py3-none-any.whl (7.0 MB)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Using cached argcomplete-3.5.0-py3-none-any.whl (43 kB)\n",
      "Using cached azure_monitor_opentelemetry_exporter-1.0.0b28-py2.py3-none-any.whl (139 kB)\n",
      "Using cached fixedint-0.1.6-py3-none-any.whl (12 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached flask-3.0.3-py3-none-any.whl (101 kB)\n",
      "Using cached Flask_Cors-4.0.1-py2.py3-none-any.whl (14 kB)\n",
      "Using cached flask_restx-1.3.0-py2.py3-none-any.whl (2.8 MB)\n",
      "Using cached keyring-24.3.1-py3-none-any.whl (38 kB)\n",
      "Using cached msal_extensions-1.2.0-py3-none-any.whl (19 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_http-1.26.0-py3-none-any.whl (16 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl (17 kB)\n",
      "Using cached opentelemetry_proto-1.26.0-py3-none-any.whl (52 kB)\n",
      "Using cached psutil-5.9.8-cp37-abi3-win_amd64.whl (255 kB)\n",
      "Using cached pydash-7.0.7-py3-none-any.whl (110 kB)\n",
      "Using cached ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
      "Using cached strictyaml-1.7.3-py3-none-any.whl (123 kB)\n",
      "Using cached waitress-2.1.2-py3-none-any.whl (57 kB)\n",
      "Using cached docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Using cached ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "Using cached aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached opentelemetry_api-1.26.0-py3-none-any.whl (61 kB)\n",
      "Using cached importlib_metadata-8.0.0-py3-none-any.whl (24 kB)\n",
      "Using cached opentelemetry_sdk-1.26.0-py3-none-any.whl (109 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl (138 kB)\n",
      "Using cached portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Using cached pywin32_ctypes-0.2.3-py3-none-any.whl (30 kB)\n",
      "Using cached ruamel.yaml.clib-0.2.8-cp311-cp311-win_amd64.whl (118 kB)\n",
      "Downloading werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
      "Downloading importlib_resources-6.4.4-py3-none-any.whl (35 kB)\n",
      "Using cached jaraco.classes-3.4.0-py3-none-any.whl (6.8 kB)\n",
      "Using cached protobuf-4.25.4-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Using cached wrapt-1.16.0-cp311-cp311-win_amd64.whl (37 kB)\n",
      "Downloading zipp-3.20.1-py3-none-any.whl (9.0 kB)\n",
      "Using cached more_itertools-10.4.0-py3-none-any.whl (60 kB)\n",
      "Installing collected packages: ply, fixedint, filetype, aniso8601, zipp, wrapt, Werkzeug, websocket-client, waitress, ruamel.yaml.clib, pywin32-ctypes, pydash, psutil, protobuf, portalocker, more-itertools, jsonpath_ng, itsdangerous, isort, importlib-resources, docstring_parser, argcomplete, strictyaml, ruamel.yaml, opentelemetry-proto, jaraco.classes, importlib-metadata, googleapis-common-protos, flask, deprecated, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, keyring, flask-cors, aiohttp_retry, opentelemetry-semantic-conventions, flask-restx, opentelemetry-sdk, msal-extensions, promptflow-tracing, opentelemetry-exporter-otlp-proto-http, azure-monitor-opentelemetry-exporter, azure-identity, promptflow-core, promptflow-devkit, promptflow-evals\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 6.0.0\n",
      "    Uninstalling psutil-6.0.0:\n",
      "      Successfully uninstalled psutil-6.0.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.27.4\n",
      "    Uninstalling protobuf-5.27.4:\n",
      "      Successfully uninstalled protobuf-5.27.4\n",
      "Successfully installed Werkzeug-3.0.4 aiohttp_retry-2.8.3 aniso8601-9.0.1 argcomplete-3.5.0 azure-identity-1.17.1 azure-monitor-opentelemetry-exporter-1.0.0b28 deprecated-1.2.14 docstring_parser-0.16 filetype-1.2.0 fixedint-0.1.6 flask-3.0.3 flask-cors-4.0.1 flask-restx-1.3.0 googleapis-common-protos-1.65.0 importlib-metadata-8.0.0 importlib-resources-6.4.4 isort-5.13.2 itsdangerous-2.2.0 jaraco.classes-3.4.0 jsonpath_ng-1.6.1 keyring-24.3.1 more-itertools-10.4.0 msal-extensions-1.2.0 opentelemetry-api-1.26.0 opentelemetry-exporter-otlp-proto-common-1.26.0 opentelemetry-exporter-otlp-proto-http-1.26.0 opentelemetry-proto-1.26.0 opentelemetry-sdk-1.26.0 opentelemetry-semantic-conventions-0.47b0 ply-3.11 portalocker-2.10.1 promptflow-core-1.15.0 promptflow-devkit-1.15.0 promptflow-evals-0.3.2 promptflow-tracing-1.15.0 protobuf-4.25.4 psutil-5.9.8 pydash-7.0.7 pywin32-ctypes-0.2.3 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.8 strictyaml-1.7.3 waitress-2.1.2 websocket-client-1.8.0 wrapt-1.16.0 zipp-3.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\hifazhassan\\workspace\\workshops\\AzureOpenAI-Workshop-Labs-1\\.venv\\Lib\\site-packages\\~sutil'.\n",
      "  You can safely remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\hifazhassan\\workspace\\workshops\\azureopenai-workshop-labs-1\\.venv\\lib\\site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install promptflow-evals\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from promptflow.core import AzureOpenAIModelConfiguration\n",
    "from promptflow.evals.evaluators import GroundednessEvaluator\n",
    "from promptflow.evals.evaluators import RelevanceEvaluator\n",
    "from promptflow.evals.evaluate import evaluate\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"azure.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = AzureOpenAIModelConfiguration(\n",
    "    azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_deployment=os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Groundedness Evaluator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpt_groundedness': 5.0}\n"
     ]
    }
   ],
   "source": [
    "# Initialzing Relevance Evaluator\n",
    "groundedness_eval = GroundednessEvaluator(model_config)\n",
    "# Running Relevance Evaluator on single input row\n",
    "groundedness_score = groundedness_eval(\n",
    "    answer=\"The Alpine Explorer Tent is the most waterproof.\",\n",
    "    context=\"From the our product list,\"\n",
    "    \" the alpine explorer tent is the most waterproof.\"\n",
    "    \" The Adventure Dining Table has higher weight.\",\n",
    "    question=\"Which tent is the most waterproof?\",\n",
    ")\n",
    "print(groundedness_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Relevance Evaluator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpt_relevance': 5.0}\n"
     ]
    }
   ],
   "source": [
    "# Initialzing Relevance Evaluator\n",
    "relevance_eval = RelevanceEvaluator(model_config)\n",
    "# Running Relevance Evaluator on single input row\n",
    "relevance_score = relevance_eval(\n",
    "    answer=\"The Alpine Explorer Tent is the most waterproof.\",\n",
    "    context=\"From the our product list,\"\n",
    "    \" the alpine explorer tent is the most waterproof.\"\n",
    "    \" The Adventure Dining Table has higher weight.\",\n",
    "    question=\"Which tent is the most waterproof?\",\n",
    ")\n",
    "print(relevance_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Batch Evaluator using JSONL file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prompt flow service...\n",
      "Starting prompt flow service...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-08-28 23:42:48 +0800][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2024-08-28 23:42:48 +0800][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run promptflow_evals_evaluators_groundedness_groundedness_asyncgroundednessevaluator_9mvzk47s_20240828_234233_787145, log path: C:\\Users\\hifazhassan\\.promptflow\\.runs\\promptflow_evals_evaluators_groundedness_groundedness_asyncgroundednessevaluator_9mvzk47s_20240828_234233_787145\\logs.txt\n",
      "[2024-08-28 23:42:48 +0800][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2024-08-28 23:42:48 +0800][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run promptflow_evals_evaluators_relevance_relevance_asyncrelevanceevaluator_vvk2hxjb_20240828_234233_787145, log path: C:\\Users\\hifazhassan\\.promptflow\\.runs\\promptflow_evals_evaluators_relevance_relevance_asyncrelevanceevaluator_vvk2hxjb_20240828_234233_787145\\logs.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can stop the prompt flow service with the following command:'\u001b[1mpf service stop\u001b[0m'.\n",
      "\n",
      "You can view the traces in local from http://127.0.0.1:23334/v1.0/ui/traces/?#run=promptflow_evals_evaluators_groundedness_groundedness_asyncgroundednessevaluator_9mvzk47s_20240828_234233_787145\n",
      "You can stop the prompt flow service with the following command:'\u001b[1mpf service stop\u001b[0m'.\n",
      "\n",
      "You can view the traces in local from http://127.0.0.1:23334/v1.0/ui/traces/?#run=promptflow_evals_evaluators_relevance_relevance_asyncrelevanceevaluator_vvk2hxjb_20240828_234233_787145\n",
      "2024-08-28 23:42:49 +0800   29708 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2024-08-28 23:42:49 +0800   29708 execution.bulk     INFO     The timeout for the batch run is 3600 seconds.\n",
      "2024-08-28 23:42:49 +0800   29708 execution.bulk     INFO     Current system's available memory is 10870.91796875MB, memory consumption of current process is 206.08203125MB, estimated available worker count is 10870.91796875/206.08203125 = 52\n",
      "2024-08-28 23:42:49 +0800   29708 execution.bulk     INFO     Set process count to 4 by taking the minimum value among the factors of {'default_worker_count': 4, 'row_count': 6, 'estimated_worker_count_based_on_memory_usage': 52}.\n",
      "2024-08-28 23:42:52 +0800   29708 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(39848)-Line number(0) start execution.\n",
      "2024-08-28 23:42:52 +0800   29708 execution.bulk     INFO     Process name(SpawnProcess-7)-Process id(12836)-Line number(1) start execution.\n",
      "2024-08-28 23:42:52 +0800   29708 execution.bulk     INFO     Process name(SpawnProcess-6)-Process id(25732)-Line number(2) start execution.\n",
      "2024-08-28 23:42:52 +0800   29708 execution.bulk     INFO     Process name(SpawnProcess-9)-Process id(3900)-Line number(3) start execution.\n",
      "2024-08-28 23:42:56 +0800   29708 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(39848)-Line number(0) completed.\n",
      "2024-08-28 23:42:56 +0800   29708 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(39848)-Line number(4) start execution.\n",
      "2024-08-28 23:42:57 +0800   29708 execution.bulk     INFO     Finished 1 / 6 lines.\n",
      "2024-08-28 23:42:57 +0800   29708 execution.bulk     INFO     Average execution time for completed lines: 5.06 seconds. Estimated time for incomplete lines: 25.3 seconds.\n",
      "2024-08-28 23:42:58 +0800   29708 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(39848)-Line number(4) completed.\n",
      "2024-08-28 23:42:58 +0800   29708 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(39848)-Line number(5) start execution.\n",
      "2024-08-28 23:42:58 +0800   29708 execution.bulk     INFO     Finished 2 / 6 lines.\n",
      "2024-08-28 23:42:58 +0800   29708 execution.bulk     INFO     Average execution time for completed lines: 3.04 seconds. Estimated time for incomplete lines: 12.16 seconds.\n",
      "2024-08-28 23:43:00 +0800   29708 execution.bulk     INFO     Process name(SpawnProcess-6)-Process id(25732)-Line number(2) completed.\n",
      "2024-08-28 23:43:00 +0800   29708 execution.bulk     INFO     Process name(SpawnProcess-7)-Process id(12836)-Line number(1) completed.\n",
      "2024-08-28 23:43:00 +0800   29708 execution.bulk     INFO     Process name(SpawnProcess-9)-Process id(3900)-Line number(3) completed.\n",
      "2024-08-28 23:43:00 +0800   29708 execution.bulk     INFO     Finished 5 / 6 lines.\n",
      "2024-08-28 23:43:00 +0800   29708 execution.bulk     INFO     Average execution time for completed lines: 1.62 seconds. Estimated time for incomplete lines: 1.62 seconds.\n",
      "2024-08-28 23:43:00 +0800   29708 execution.bulk     INFO     Process name(SpawnProcess-4)-Process id(39848)-Line number(5) completed.\n",
      "2024-08-28 23:43:01 +0800   40204 execution.bulk     INFO     The process [40204] has received a terminate signal.\n",
      "2024-08-28 23:43:01 +0800   23648 execution.bulk     INFO     The process [23648] has received a terminate signal.\n",
      "2024-08-28 23:43:01 +0800   19136 execution.bulk     INFO     The process [19136] has received a terminate signal.\n",
      "2024-08-28 23:43:01 +0800   29708 execution.bulk     INFO     Finished 6 / 6 lines.\n",
      "2024-08-28 23:43:01 +0800   29708 execution.bulk     INFO     Average execution time for completed lines: 1.52 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2024-08-28 23:43:01 +0800   29708 execution.bulk     INFO     The thread monitoring the process [39848-SpawnProcess-4] will be terminated.\n",
      "2024-08-28 23:43:01 +0800   29708 execution.bulk     INFO     The thread monitoring the process [25732-SpawnProcess-6] will be terminated.\n",
      "2024-08-28 23:43:01 +0800   29708 execution.bulk     INFO     The thread monitoring the process [12836-SpawnProcess-7] will be terminated.\n",
      "2024-08-28 23:43:01 +0800   29708 execution.bulk     INFO     The thread monitoring the process [3900-SpawnProcess-9] will be terminated.\n",
      "2024-08-28 23:43:01 +0800   39848 execution.bulk     INFO     The process [39848] has received a terminate signal.\n",
      "2024-08-28 23:43:01 +0800   25732 execution.bulk     INFO     The process [25732] has received a terminate signal.\n",
      "2024-08-28 23:43:01 +0800    3900 execution.bulk     INFO     The process [3900] has received a terminate signal.\n",
      "\n",
      "2024-08-28 23:43:02 +0800   29708 execution.bulk     INFO     Process 25732 terminated.\n",
      "2024-08-28 23:43:02 +0800   29708 execution.bulk     INFO     Process 12836 terminated.\n",
      "2024-08-28 23:43:02 +0800   29708 execution.bulk     INFO     Process 3900 terminated.\n",
      "2024-08-28 23:43:02 +0800   29708 execution.bulk     INFO     Process 39848 terminated.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"promptflow_evals_evaluators_relevance_relevance_asyncrelevanceevaluator_vvk2hxjb_20240828_234233_787145\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2024-08-28 23:42:33.785145+08:00\"\n",
      "Duration: \"0:00:29.135864\"\n",
      "Output path: \"C:\\Users\\hifazhassan\\.promptflow\\.runs\\promptflow_evals_evaluators_relevance_relevance_asyncrelevanceevaluator_vvk2hxjb_20240828_234233_787145\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-08-28 23:43:03 +0800][promptflow.evals.evaluate._utils][ERROR] - Unable to log traces as trace destination was not defined.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-28 23:42:49 +0800   29708 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2024-08-28 23:42:49 +0800   29708 execution.bulk     INFO     The timeout for the batch run is 3600 seconds.\n",
      "2024-08-28 23:42:49 +0800   29708 execution.bulk     INFO     Current system's available memory is 10877.015625MB, memory consumption of current process is 205.5390625MB, estimated available worker count is 10877.015625/205.5390625 = 52\n",
      "2024-08-28 23:42:49 +0800   29708 execution.bulk     INFO     Set process count to 4 by taking the minimum value among the factors of {'default_worker_count': 4, 'row_count': 6, 'estimated_worker_count_based_on_memory_usage': 52}.\n",
      "2024-08-28 23:42:52 +0800   29708 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(40068)-Line number(0) start execution.\n",
      "2024-08-28 23:42:52 +0800   29708 execution.bulk     INFO     Process name(SpawnProcess-10)-Process id(23648)-Line number(1) start execution.\n",
      "2024-08-28 23:42:52 +0800   29708 execution.bulk     INFO     Process name(SpawnProcess-8)-Process id(40204)-Line number(2) start execution.\n",
      "2024-08-28 23:42:52 +0800   29708 execution.bulk     INFO     Process name(SpawnProcess-5)-Process id(19136)-Line number(3) start execution.\n",
      "2024-08-28 23:42:56 +0800   29708 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(40068)-Line number(0) completed.\n",
      "2024-08-28 23:42:56 +0800   29708 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(40068)-Line number(4) start execution.\n",
      "2024-08-28 23:42:57 +0800   29708 execution.bulk     INFO     Finished 1 / 6 lines.\n",
      "2024-08-28 23:42:57 +0800   29708 execution.bulk     INFO     Average execution time for completed lines: 5.04 seconds. Estimated time for incomplete lines: 25.2 seconds.\n",
      "2024-08-28 23:42:58 +0800   29708 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(40068)-Line number(4) completed.\n",
      "2024-08-28 23:42:58 +0800   29708 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(40068)-Line number(5) start execution.\n",
      "2024-08-28 23:42:58 +0800   29708 execution.bulk     INFO     Finished 2 / 6 lines.\n",
      "2024-08-28 23:42:58 +0800   29708 execution.bulk     INFO     Average execution time for completed lines: 3.03 seconds. Estimated time for incomplete lines: 12.12 seconds.\n",
      "2024-08-28 23:43:00 +0800   29708 execution.bulk     INFO     Process name(SpawnProcess-5)-Process id(19136)-Line number(3) completed.\n",
      "2024-08-28 23:43:00 +0800   29708 execution.bulk     INFO     Process name(SpawnProcess-8)-Process id(40204)-Line number(2) completed.\n",
      "2024-08-28 23:43:00 +0800   29708 execution.bulk     INFO     Process name(SpawnProcess-10)-Process id(23648)-Line number(1) completed.\n",
      "2024-08-28 23:43:00 +0800   29708 execution.bulk     INFO     Finished 5 / 6 lines.\n",
      "2024-08-28 23:43:00 +0800   29708 execution.bulk     INFO     Average execution time for completed lines: 1.61 seconds. Estimated time for incomplete lines: 1.61 seconds.\n",
      "2024-08-28 23:43:00 +0800   29708 execution.bulk     INFO     Process name(SpawnProcess-3)-Process id(40068)-Line number(5) completed.\n",
      "2024-08-28 23:43:01 +0800   29708 execution.bulk     INFO     Finished 6 / 6 lines.\n",
      "2024-08-28 23:43:01 +0800   29708 execution.bulk     INFO     Average execution time for completed lines: 1.51 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2024-08-28 23:43:01 +0800   29708 execution.bulk     INFO     The thread monitoring the process [19136-SpawnProcess-5] will be terminated.\n",
      "2024-08-28 23:43:01 +0800   29708 execution.bulk     INFO     The thread monitoring the process [40204-SpawnProcess-8] will be terminated.\n",
      "2024-08-28 23:43:01 +0800   29708 execution.bulk     INFO     The thread monitoring the process [23648-SpawnProcess-10] will be terminated.\n",
      "2024-08-28 23:43:01 +0800   29708 execution.bulk     INFO     The thread monitoring the process [40068-SpawnProcess-3] will be terminated.\n",
      "2024-08-28 23:43:02 +0800   29708 execution.bulk     INFO     Process 19136 terminated.\n",
      "2024-08-28 23:43:02 +0800   29708 execution.bulk     INFO     Process 40068 terminated.\n",
      "2024-08-28 23:43:02 +0800   29708 execution.bulk     INFO     Process 23648 terminated.\n",
      "2024-08-28 23:43:02 +0800   29708 execution.bulk     INFO     Process 40204 terminated.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"promptflow_evals_evaluators_groundedness_groundedness_asyncgroundednessevaluator_9mvzk47s_20240828_234233_787145\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2024-08-28 23:42:33.785145+08:00\"\n",
      "Duration: \"0:00:29.132859\"\n",
      "Output path: \"C:\\Users\\hifazhassan\\.promptflow\\.runs\\promptflow_evals_evaluators_groundedness_groundedness_asyncgroundednessevaluator_9mvzk47s_20240828_234233_787145\"\n",
      "\n",
      "{'rows': [{'inputs.question': 'Which tent is the most waterproof?', 'inputs.context': 'From the our product list, the alpine explorer tent is the most waterproof. The Adventure Dining Table has higher weight.', 'inputs.answer': 'The Alpine Explorer Tent is the most waterproof.', 'outputs.relevance.gpt_relevance': 5, 'outputs.groundedness.gpt_groundedness': 5}, {'inputs.question': 'Which tent is the most waterproof?', 'inputs.context': 'From the our product list, the alpine explorer tent is the most waterproof. The Adventure Dining Table has higher weight.', 'inputs.answer': 'The Manua Kea Explorer Tent is the most waterproof.', 'outputs.relevance.gpt_relevance': 1, 'outputs.groundedness.gpt_groundedness': 1}, {'inputs.question': 'What is the capital of France?', 'inputs.context': 'France is in EU', 'inputs.answer': 'Nepal', 'outputs.relevance.gpt_relevance': 1, 'outputs.groundedness.gpt_groundedness': 1}, {'inputs.question': 'What is the speed of light?', 'inputs.context': 'Light travels at a constant speed in a vacuum.', 'inputs.answer': 'The speed of light is approximately 299,792,458 meters per second.', 'outputs.relevance.gpt_relevance': 5, 'outputs.groundedness.gpt_groundedness': 5}, {'inputs.question': 'Summarize the transcription between patient and doctor.', 'inputs.context': '\\nDoctor: How are you feeling.\\nPatient: Not great, I have high fever\\nDoctor: I understand, do you have headache?\\nPatient: No\\nDoctor: Take Panadol 2 times a day and if fever is above 40 degrees take Ibuprofen\\nPatient: For how many days?\\nDoctor: 1 week and visit me again if fever persists\\nPatient: Thanks', 'inputs.answer': 'The patient reported having a high fever but no headache. The doctor advised taking Panadol twice daily and Ibuprofen if the fever exceeds 40 degrees. The doctor recommended this treatment for one week and suggested a follow-up visit if the fever persists.', 'outputs.relevance.gpt_relevance': 5, 'outputs.groundedness.gpt_groundedness': 5}, {'inputs.question': 'Summarize the transcription between patient and doctor.', 'inputs.context': '\\nDoctor: How are you feeling.\\nPatient: Not great, I have high fever\\nDoctor: I understand, do you have headache?\\nPatient: No\\nDoctor: Take Panadol 2 times a day and if fever is above 40 degrees take Ibuprofen\\nPatient: For how many days?\\nDoctor: 1 week and visit me again if fever persists\\nPatient: Thanks', 'inputs.answer': 'The patient reported having a high fever but no headache. The doctor advised taking Panadol twice daily.', 'outputs.relevance.gpt_relevance': 3, 'outputs.groundedness.gpt_groundedness': 5}], 'metrics': {'relevance.gpt_relevance': 3.3333333333333335, 'groundedness.gpt_groundedness': 3.6666666666666665}, 'studio_url': None}\n"
     ]
    }
   ],
   "source": [
    "# provide the absolute path to the data file, currently promptflow-evals does not suport relative paths\n",
    "data_path = \"C:\\\\Users\\hifazhassan\\workspace\\workshops\\AzureOpenAI-Workshop-Labs-1\\labs-advanced\\evaluation\\data\\sample_qa.jsonl\"\n",
    "result = evaluate(\n",
    "    evaluation_name=\"test-eval\",\n",
    "    data=data_path, # provide your data here\n",
    "    evaluators={\n",
    "        \"relevance\": relevance_eval,\n",
    "        \"groundedness\": groundedness_eval,\n",
    "        # \"coherence\": coherence_eval,\n",
    "        # \"fluency\": fluency_eval\n",
    "    },\n",
    "    # column mapping\n",
    "    evaluator_config={\n",
    "        \"default\": {\n",
    "            \"question\": \"${data.question}\",\n",
    "            \"context\": \"${data.context}\",\n",
    "            \"answer\": \"${data.answer}\"\n",
    "        }\n",
    "    }\n",
    "    # # Optionally provide your AI Studio project information to track your evaluation results in your Azure AI studio project\n",
    "    #azure_ai_project = azure_ai_project,\n",
    "    # Optionally provide an output path to dump a json of metric summary, row level data and metric and studio URL\n",
    "    #output_path=output_path\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
